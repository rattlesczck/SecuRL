{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nasim\n",
        "!pip install neo4j\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc1yow49dzPy",
        "outputId": "cfa60469-4600-4681-9385-fc70eaacca82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nasim\n",
            "  Downloading nasim-0.12.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.11/dist-packages (from nasim) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from nasim) (1.26.4)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from nasim) (6.0.2)\n",
            "Requirement already satisfied: prettytable>=0.7 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.14.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable>=0.7->nasim) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1->nasim) (1.17.0)\n",
            "Downloading nasim-0.12.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nasim\n",
            "Successfully installed nasim-0.12.0\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.1)\n",
            "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neo4j\n",
            "Successfully installed neo4j-5.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# ====================================\n",
        "#  1️⃣ NEO4J CONFIGURATION & DATA FETCHING\n",
        "# ====================================\n",
        "\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:13454\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "class Neo4jConnector:\n",
        "    \"\"\"Handles interaction with Neo4j database for retrieving threat details.\"\"\"\n",
        "\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def get_random_cve(self):\n",
        "        \"\"\"Retrieve a random CVE from the Neo4j database.\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (cve:CVE)\n",
        "        RETURN cve.ID AS CVE_ID, cve.Name AS CVE_Name, cve.Description AS CVE_Description\n",
        "        ORDER BY rand()\n",
        "        LIMIT 1\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return result.single()\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "\n",
        "# ====================================\n",
        "#  2️⃣ DQN MODEL\n",
        "# ====================================\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \"\"\"Deep Q-Network (DQN) for learning attack strategies and detecting threats.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        return q_values\n",
        "\n",
        "# ====================================\n",
        "#  3️⃣ EXPERIENCE REPLAY BUFFER\n",
        "# ====================================\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Experience Replay Buffer for storing past transitions.\"\"\"\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# ====================================\n",
        "#  4️⃣ ACTION SELECTION (EPSILON-GREEDY)\n",
        "# ====================================\n",
        "\n",
        "def select_action(state, epsilon):\n",
        "    \"\"\"Epsilon-Greedy Policy for selecting integer actions.\"\"\"\n",
        "    if random.random() < epsilon:  # Explore\n",
        "        return int(env.action_space.sample())  # Ensure integer return\n",
        "    else:  # Exploit\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        q_values = policy_net(state_tensor)\n",
        "        return int(torch.argmax(q_values).item())  # Ensure integer return\n",
        "\n",
        "# ====================================\n",
        "#  5️⃣ TRAINING FUNCTION\n",
        "# ====================================\n",
        "\n",
        "def train_dqn():\n",
        "    \"\"\"Train the DQN using Experience Replay.\"\"\"\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor(dones)\n",
        "\n",
        "    q_values = policy_net(states).gather(1, actions).squeeze(1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        max_next_q_values = target_net(next_states).max(1)[0]\n",
        "\n",
        "    target_q_values = rewards + (GAMMA * max_next_q_values * (1 - dones))\n",
        "\n",
        "    loss = nn.MSELoss()(q_values, target_q_values)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# ====================================\n",
        "#  6️⃣ TRAINING LOOP\n",
        "# ====================================\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim)\n",
        "target_net = DQN(state_dim, action_dim)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# ✅ Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    # 🔺 Get a random CVE attack type for this episode\n",
        "    random_threat = neo4j_db.get_random_cve()\n",
        "    threat_name = random_threat[\"CVE_Name\"] if random_threat else \"Unknown Threat\"\n",
        "    threat_description = random_threat[\"CVE_Description\"] if random_threat else \"No Description Available\"\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        memory.push(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "    # 🔹 Print attack details at the end of the episode\n",
        "    print(f\" Episode {episode}: Reward = {total_reward}, Epsilon = {epsilon:.4f}\")\n",
        "    print(f\" Detected Threat: {threat_name}\")\n",
        "    print(f\" Description: {threat_description}\\n\")\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "\n",
        "# ✅ Save Model & Close DB\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"✅ Simulation Completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtsyOgRj_Ho7",
        "outputId": "5d737120-adbf-47bf-9185-73831c5d45d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Episode 0: Reward = 140.0, Epsilon = 1.0000\n",
            "🔺 Detected Threat: CVE-2021-27571\n",
            "📝 Description: ['An issue was discovered in Emote Remote Mouse through 4.0.0.0. Attackers can retrieve recently used and running applications, their icons, and their file paths. This information is sent in cleartext and is not protected by any authentication logic.']\n",
            "\n",
            "🎯 Episode 1: Reward = -50.0, Epsilon = 0.9970\n",
            "🔺 Detected Threat: CVE-2021-36770\n",
            "📝 Description: ['Encode.pm, as distributed in Perl through 5.34.0, allows local users to gain privileges via a Trojan horse Encode::ConfigLocal library (in the current working directory) that preempts dynamic module loading. Exploitation requires an unusual configuration, and certain 2021 versions of Encode.pm (3.05 through 3.11). This issue occurs because the || operator evaluates @INC in a scalar context, and thus @INC has only an integer value.']\n",
            "\n",
            "🎯 Episode 2: Reward = 56.0, Epsilon = 0.9940\n",
            "🔺 Detected Threat: CVE-2021-29068\n",
            "📝 Description: ['Certain NETGEAR devices are affected by a buffer overflow by an authenticated user. This affects R6700v3 before 1.0.4.98, R6400v2 before 1.0.4.98, R7000 before 1.0.11.106, R6900P before 1.3.2.124, R7000P before 1.3.2.124, R7900 before 1.0.4.26, R7850 before 1.0.5.60, R8000 before 1.0.4.58, RS400 before 1.5.0.48, R6400 before 1.0.1.62, R6700 before 1.0.2.16, R6900 before 1.0.2.16, MK60 before 1.0.5.102, MR60 before 1.0.5.102, MS60 before 1.0.5.102, CBR40 before 2.5.0.10, R8000P before 1.4.1.62, R7960P before 1.4.1.62, R7900P before 1.4.1.62, RAX15 before 1.0.1.64, RAX20 before 1.0.1.64, RAX75 before 1.0.3.102, RAX80 before 1.0.3.102, RAX200 before 1.0.2.102, RAX45 before 1.0.2.64, RAX50 before 1.0.2.64, EX7500 before 1.0.0.68, EAX80 before 1.0.1.62, EAX20 before 1.0.0.36, RBK752 before 3.2.16.6, RBK753 before 3.2.16.6, RBK753S before 3.2.16.6, RBK754 before 3.2.16.6, RBR750 before 3.2.16.6, RBS750 before 3.2.16.6, RBK852 before 3.2.16.6, RBK853 before 3.2.16.6, RBK854 before 3.2.16.6, RBR850 before 3.2.16.6, RBS850 before 3.2.16.6, RBR840 before 3.2.16.6, RBS840 before 3.2.16.6, R6120 before 1.0.0.70, R6220 before 1.1.0.100, R6230 before 1.1.0.100, R6260 before 1.1.0.76, R6850 before 1.1.0.76, R6350 before 1.1.0.76, R6330 before 1.1.0.76, D7800 before 1.0.1.58, RBK50 before 2.6.1.40, RBR50 before 2.6.1.40, RBS50 before 2.6.1.40, RBK40 before 2.6.1.36, RBR40 before 2.6.1.36, RBS40 before 2.6.1.38, RBK23 before 2.6.1.36, RBR20 before 2.6.1.38, RBS20 before 2.6.1.38, RBK12 before 2.6.1.44, RBK13 before 2.6.1.44, RBK14 before 2.6.1.44, RBK15 before 2.6.1.44, RBR10 before 2.6.1.44, RBS10 before 2.6.1.44, R6800 before 1.2.0.72, R6900v2 before 1.2.0.72, R6700v2 before 1.2.0.72, R7200 before 1.2.0.72, R7350 before 1.2.0.72, R7400 before 1.2.0.72, R7450 before 1.2.0.72, AC2100 before 1.2.0.72, AC2400 before 1.2.0.72, AC2600 before 1.2.0.72, R7800 before 1.0.2.74, R8900 before 1.0.5.24, R9000 before 1.0.5.24, RAX120 before 1.0.1.136, XR450 before 2.3.2.66, XR500 before 2.3.2.66, XR700 before 1.0.1.34, and XR300 before 1.0.3.50.']\n",
            "\n",
            "🎯 Episode 3: Reward = 141.0, Epsilon = 0.9910\n",
            "🔺 Detected Threat: CVE-2021-26715\n",
            "📝 Description: ['The OpenID Connect server implementation for MITREid Connect through 1.3.3 contains a Server Side Request Forgery (SSRF) vulnerability. The vulnerability arises due to unsafe usage of the logo_uri parameter in the Dynamic Client Registration request. An unauthenticated attacker can make a HTTP request from the vulnerable server to any address in the internal network and obtain its response (which might, for example, have a JavaScript payload for resultant XSS). The issue can be exploited to bypass network boundaries, obtain sensitive data, or attack other hosts in the internal network.']\n",
            "\n",
            "🎯 Episode 4: Reward = 81.0, Epsilon = 0.9881\n",
            "🔺 Detected Threat: CVE-2021-31434\n",
            "📝 Description: ['This vulnerability allows remote attackers to execute arbitrary code on affected installations of Foxit Studio Photo 3.6.6.931. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the parsing of JPM files. The issue results from the lack of proper validation of user-supplied data, which can result in a write past the end of an allocated structure. An attacker can leverage this vulnerability to execute code in the context of the current process. Was ZDI-CAN-12377.']\n",
            "\n",
            "🎯 Episode 5: Reward = 95.0, Epsilon = 0.9851\n",
            "🔺 Detected Threat: CVE-2021-20085\n",
            "📝 Description: [\"Improperly Controlled Modification of Object Prototype Attributes ('Prototype Pollution') in backbone-query-parameters 0.4.0 allows a malicious user to inject properties into Object.prototype.\"]\n",
            "\n",
            "🎯 Episode 6: Reward = 62.0, Epsilon = 0.9821\n",
            "🔺 Detected Threat: CVE-2021-36009\n",
            "📝 Description: ['Adobe Illustrator version 25.2.3 (and earlier) is affected by an memory corruption vulnerability when parsing a specially crafted file. An unauthenticated attacker could leverage this vulnerability to achieve arbitrary code execution in the context of the current user. Exploitation of this issue requires user interaction in that a victim must open a malicious file.']\n",
            "\n",
            "🎯 Episode 7: Reward = 103.0, Epsilon = 0.9792\n",
            "🔺 Detected Threat: CVE-2021-34847\n",
            "📝 Description: ['This vulnerability allows remote attackers to execute arbitrary code on affected installations of Foxit PDF Reader 11.0.0.49893. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the handling of Annotation objects. The issue results from the lack of validating the existence of an object prior to performing operations on the object. An attacker can leverage this vulnerability to execute code in the context of the current process. Was ZDI-CAN-14270.']\n",
            "\n",
            "🎯 Episode 8: Reward = 114.0, Epsilon = 0.9763\n",
            "🔺 Detected Threat: CVE-2021-37667\n",
            "📝 Description: ['TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.UnicodeEncode`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/unicode_ops.cc#L533-L539) reads the first dimension of the `input_splits` tensor before validating that this tensor is not empty. We have patched the issue in GitHub commit 2e0ee46f1a47675152d3d865797a18358881d7a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.']\n",
            "\n",
            "🎯 Episode 9: Reward = 166.0, Epsilon = 0.9733\n",
            "🔺 Detected Threat: CVE-2021-3539\n",
            "📝 Description: ['EspoCRM 6.1.6 and prior suffers from a persistent (type II) cross-site scripting (XSS) vulnerability in processing user-supplied avatar images. This issue was fixed in version 6.1.7 of the product.']\n",
            "\n",
            "🎯 Episode 10: Reward = 139.0, Epsilon = 0.9704\n",
            "🔺 Detected Threat: CVE-2021-34298\n",
            "📝 Description: ['A vulnerability has been identified in JT2Go (All versions < V13.2), Teamcenter Visualization (All versions < V13.2). The BMP_Loader.dll library in affected applications lacks proper validation of user-supplied data prior to performing further free operations on an object when parsing BMP files. An attacker could leverage this vulnerability to execute code in the context of the current process. (ZDI-CAN-13060)']\n",
            "\n",
            "🎯 Episode 11: Reward = 60.0, Epsilon = 0.9675\n",
            "🔺 Detected Threat: CVE-2021-21672\n",
            "📝 Description: ['Jenkins Selenium HTML report Plugin 1.0 and earlier does not configure its XML parser to prevent XML external entity (XXE) attacks.']\n",
            "\n",
            "🎯 Episode 12: Reward = 62.0, Epsilon = 0.9646\n",
            "🔺 Detected Threat: CVE-2021-0584\n",
            "📝 Description: ['In verifyBufferObject of Parcel.cpp, there is a possible out of bounds read due to an improper input validation. This could lead to local information disclosure with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android-11 Android-8.1 Android-9 Android-10Android ID: A-179289794']\n",
            "\n",
            "🎯 Episode 13: Reward = 71.0, Epsilon = 0.9617\n",
            "🔺 Detected Threat: CVE-2021-33768\n",
            "📝 Description: ['Microsoft Exchange Server Elevation of Privilege Vulnerability This CVE ID is unique from CVE-2021-34470, CVE-2021-34523.']\n",
            "\n",
            "🎯 Episode 14: Reward = 115.0, Epsilon = 0.9588\n",
            "🔺 Detected Threat: CVE-2021-34707\n",
            "📝 Description: ['A vulnerability in the REST API of Cisco Evolved Programmable Network Manager (EPNM) could allow an authenticated, remote attacker to access sensitive data on an affected system. This vulnerability exists because the application does not sufficiently protect sensitive data when responding to an API request. An attacker could exploit the vulnerability by sending a specific API request to the affected application. A successful exploit could allow the attacker to obtain sensitive information about the application.']\n",
            "\n",
            "🎯 Episode 15: Reward = 60.0, Epsilon = 0.9559\n",
            "🔺 Detected Threat: CVE-2021-27245\n",
            "📝 Description: ['This vulnerability allows a firewall bypass on affected installations of TP-Link Archer A7 prior to Archer C7(US)_V5_210125 and Archer A7(US)_V5_200220 AC1750 routers. Authentication is not required to exploit this vulnerability. The specific flaw exists within the handling of IPv6 connections. The issue results from the lack of proper filtering of IPv6 SSH connections. An attacker can leverage this in conjunction with other vulnerabilities to execute code in the context of root. Was ZDI-CAN-12309.']\n",
            "\n",
            "🎯 Episode 16: Reward = 103.0, Epsilon = 0.9531\n",
            "🔺 Detected Threat: CVE-2021-31407\n",
            "📝 Description: ['Vulnerability in OSGi integration in com.vaadin:flow-server versions 1.2.0 through 2.4.7 (Vaadin 12.0.0 through 14.4.9), and 6.0.0 through 6.0.1 (Vaadin 19.0.0) allows attacker to access application classes and resources on the server via crafted HTTP request.']\n",
            "\n",
            "🎯 Episode 17: Reward = 34.0, Epsilon = 0.9502\n",
            "🔺 Detected Threat: CVE-2021-28976\n",
            "📝 Description: ['Remote Code Execution vulnerability in GetSimpleCMS before 3.3.16 in admin/upload.php via phar filess.']\n",
            "\n",
            "🎯 Episode 18: Reward = 61.0, Epsilon = 0.9474\n",
            "🔺 Detected Threat: CVE-2021-30522\n",
            "📝 Description: ['Use after free in WebAudio in Google Chrome prior to 91.0.4472.77 allowed a remote attacker to potentially exploit heap corruption via a crafted HTML page.']\n",
            "\n",
            "🎯 Episode 19: Reward = 87.0, Epsilon = 0.9445\n",
            "🔺 Detected Threat: CVE-2021-28857\n",
            "📝 Description: [\"TP-Link's TL-WPA4220 4.0.2 Build 20180308 Rel.37064 username and password are sent via the cookie.\"]\n",
            "\n",
            "🎯 Episode 20: Reward = 128.0, Epsilon = 0.9417\n",
            "🔺 Detected Threat: CVE-2021-25414\n",
            "📝 Description: ['Improper sanitization of incoming intent in Samsung Contacts prior to SMR JUN-2021 Release 1 allows local attackers to copy or overwrite arbitrary files with Samsung Contacts privilege.']\n",
            "\n",
            "🎯 Episode 21: Reward = 125.0, Epsilon = 0.9389\n",
            "🔺 Detected Threat: CVE-2021-22181\n",
            "📝 Description: ['A denial of service vulnerability in GitLab CE/EE affecting all versions since 11.8 allows an attacker to create a recursive pipeline relationship and exhaust resources.']\n",
            "\n",
            "🎯 Episode 22: Reward = -45.0, Epsilon = 0.9360\n",
            "🔺 Detected Threat: CVE-2021-27048\n",
            "📝 Description: ['HEVC Video Extensions Remote Code Execution Vulnerability This CVE ID is unique from CVE-2021-24089, CVE-2021-24110, CVE-2021-26902, CVE-2021-27047, CVE-2021-27049, CVE-2021-27050, CVE-2021-27051, CVE-2021-27061, CVE-2021-27062.']\n",
            "\n",
            "🎯 Episode 23: Reward = 160.0, Epsilon = 0.9332\n",
            "🔺 Detected Threat: CVE-2021-20533\n",
            "📝 Description: ['IBM Security Verify Access Docker 10.0.0 could allow a remote authenticated attacker to execute arbitrary commands on the system by sending a specially crafted request. IBM X-Force ID: 198813']\n",
            "\n",
            "🎯 Episode 24: Reward = 106.0, Epsilon = 0.9304\n",
            "🔺 Detected Threat: CVE-2021-21722\n",
            "📝 Description: ['A ZTE Smart STB is impacted by an information leak vulnerability. The device did not fully verify the log, so attackers could use this vulnerability to obtain sensitive user information for further information detection and attacks. This affects: ZXV10 B860A V2.1-T_V0032.1.1.04_jiangsuTelecom.']\n",
            "\n",
            "🎯 Episode 25: Reward = 136.0, Epsilon = 0.9276\n",
            "🔺 Detected Threat: CVE-2021-29063\n",
            "📝 Description: ['A Regular Expression Denial of Service (ReDOS) vulnerability was discovered in Mpmath v1.0.0 when the mpmathify function is called.']\n",
            "\n",
            "🎯 Episode 26: Reward = 108.0, Epsilon = 0.9249\n",
            "🔺 Detected Threat: CVE-2021-31442\n",
            "📝 Description: ['This vulnerability allows remote attackers to execute arbitrary code on affected installations of Foxit Reader 10.1.1.37576. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the handling of U3D objects in PDF files. The issue results from the lack of proper validation of user-supplied data, which can result in a write past the end of an allocated data structure. An attacker can leverage this vulnerability to execute code in the context of the current process. Was ZDI-CAN-13239.']\n",
            "\n",
            "🎯 Episode 27: Reward = 113.0, Epsilon = 0.9221\n",
            "🔺 Detected Threat: CVE-2021-35061\n",
            "📝 Description: ['Multiple cross-site scripting (XSS) vulnerabilities in DRK Odenwaldkreis Testerfassung March-2021 allow remote attackers to inject arbitrary web script or HTML via all parameters to HTML form fields in all components.']\n",
            "\n",
            "🎯 Episode 28: Reward = 156.0, Epsilon = 0.9193\n",
            "🔺 Detected Threat: CVE-2021-29595\n",
            "📝 Description: ['TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `DepthToSpace` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/depth_to_space.cc#L63-L69). An attacker can craft a model such that `params->block_size` is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.']\n",
            "\n",
            "🎯 Episode 29: Reward = 141.0, Epsilon = 0.9166\n",
            "🔺 Detected Threat: CVE-2021-30759\n",
            "📝 Description: ['A stack overflow was addressed with improved input validation. This issue is fixed in iOS 14.7, macOS Big Sur 11.5, watchOS 7.6, tvOS 14.7, Security Update 2021-005 Mojave, Security Update 2021-004 Catalina. Processing a maliciously crafted font file may lead to arbitrary code execution.']\n",
            "\n",
            "🎯 Episode 30: Reward = 77.0, Epsilon = 0.9138\n",
            "🔺 Detected Threat: CVE-2021-22875\n",
            "📝 Description: ['Revive Adserver before 5.1.1 is vulnerable to a reflected XSS vulnerability in stats.php via the `setPerPage` parameter.']\n",
            "\n",
            "🎯 Episode 31: Reward = 50.0, Epsilon = 0.9111\n",
            "🔺 Detected Threat: CVE-2021-39112\n",
            "📝 Description: ['Affected versions of Atlassian Jira Server and Data Center allow remote attackers to redirect users to a malicious URL via a reverse tabnapping vulnerability in the Project Shortcuts feature. The affected versions are before version 8.5.15, from version 8.6.0 before 8.13.7, from version 8.14.0 before 8.17.1, and from version 8.18.0 before 8.18.1.']\n",
            "\n",
            "🎯 Episode 32: Reward = 135.0, Epsilon = 0.9083\n",
            "🔺 Detected Threat: CVE-2021-34436\n",
            "📝 Description: ['In Eclipse Theia 0.1.1 to 0.2.0, it is possible to exploit the default build to obtain remote code execution (and XXE) via the theia-xml-extension. This extension uses lsp4xml (recently renamed to LemMinX) in order to provide language support for XML. This is installed by default.']\n",
            "\n",
            "🎯 Episode 33: Reward = -76.0, Epsilon = 0.9056\n",
            "🔺 Detected Threat: CVE-2021-21608\n",
            "📝 Description: ['Jenkins 2.274 and earlier, LTS 2.263.1 and earlier does not escape button labels in the Jenkins UI, resulting in a cross-site scripting (XSS) vulnerability exploitable by attackers with the ability to control button labels.']\n",
            "\n",
            "🎯 Episode 34: Reward = 43.0, Epsilon = 0.9029\n",
            "🔺 Detected Threat: CVE-2021-0551\n",
            "📝 Description: ['In bind of MediaControlPanel.java, there is a possible way to lock up the system UI using a malicious media file due to improper input validation. This could lead to remote denial of service with no additional execution privileges needed. User interaction is needed for exploitation.Product: AndroidVersions: Android-11Android ID: A-180518039']\n",
            "\n",
            "🎯 Episode 35: Reward = 155.0, Epsilon = 0.9002\n",
            "🔺 Detected Threat: CVE-2021-34616\n",
            "📝 Description: ['A remote arbitrary command execution vulnerability was discovered in Aruba ClearPass Policy Manager version(s): Prior to 6.10.0, 6.9.6 and 6.8.9. Aruba has released updates to ClearPass Policy Manager that address this security vulnerability.']\n",
            "\n",
            "🎯 Episode 36: Reward = 123.0, Epsilon = 0.8975\n",
            "🔺 Detected Threat: CVE-2021-30901\n",
            "📝 Description: ['** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: none. Reason: This candidate was withdrawn by the CVE program. Notes: none.']\n",
            "\n",
            "🎯 Episode 37: Reward = 110.0, Epsilon = 0.8948\n",
            "🔺 Detected Threat: CVE-2021-32645\n",
            "📝 Description: [\"Tenancy multi-tenant is an open source multi-domain controller for the Laravel web framework. In some situations, it is possible to have open redirects where users can be redirected from your site to any other site using a specially crafted URL. This is only the case for installations where the default Hostname Identification is used and the environment uses tenants that have `force_https` set to `true` (default: `false`). Version 5.7.2 contains the relevant patches to fix this bug. Stripping the URL from special characters to prevent specially crafted URL's from being redirected to. As a work around users can set the `force_https` to every tenant to `false`, however this may degrade connection security.\"]\n",
            "\n",
            "🎯 Episode 38: Reward = 168.0, Epsilon = 0.8921\n",
            "🔺 Detected Threat: CVE-2021-2315\n",
            "📝 Description: ['Vulnerability in the Oracle HTTP Server product of Oracle Fusion Middleware (component: Web Listener). Supported versions that are affected are 11.1.1.9.0, 12.2.1.3.0 and 12.2.1.4.0. Easily exploitable vulnerability allows unauthenticated attacker with network access via HTTP to compromise Oracle HTTP Server. Successful attacks require human interaction from a person other than the attacker. Successful attacks of this vulnerability can result in unauthorized update, insert or delete access to some of Oracle HTTP Server accessible data as well as unauthorized read access to a subset of Oracle HTTP Server accessible data. CVSS 3.1 Base Score 5.4 (Confidentiality and Integrity impacts). CVSS Vector: (CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:N).']\n",
            "\n",
            "🎯 Episode 39: Reward = 140.0, Epsilon = 0.8894\n",
            "🔺 Detected Threat: CVE-2021-26603\n",
            "📝 Description: ['A heap overflow issue was found in ARK library of bandisoft Co., Ltd when the Ark_DigPathA function parsed a file path. This vulnerability is due to missing support for string length check.']\n",
            "\n",
            "🎯 Episode 40: Reward = -31.0, Epsilon = 0.8868\n",
            "🔺 Detected Threat: CVE-2021-27924\n",
            "📝 Description: ['An issue was discovered in Couchbase Server 6.x through 6.6.1. The Couchbase Server UI is insecurely logging session cookies in the logs. This allows for the impersonation of a user if the log files are obtained by an attacker before a session cookie expires.']\n",
            "\n",
            "🎯 Episode 41: Reward = 136.0, Epsilon = 0.8841\n",
            "🔺 Detected Threat: CVE-2021-32655\n",
            "📝 Description: ['Nextcloud Server is a Nextcloud package that handles data storage. In versions prior to 19.0.11, 20.0.10, and 21.0.2, an attacker is able to convert a Files Drop link to a federated share. This causes an issue on the UI side of the sharing user. When the sharing user opens the sharing panel and tries to remove the \"Create\" privileges of this unexpected share, Nextcloud server would silently grant the share read privileges. The vulnerability is patched in versions 19.0.11, 20.0.10 and 21.0.2. No workarounds are known to exist.']\n",
            "\n",
            "🎯 Episode 42: Reward = 137.0, Epsilon = 0.8814\n",
            "🔺 Detected Threat: CVE-2021-34474\n",
            "📝 Description: ['Dynamics Business Central Remote Code Execution Vulnerability']\n",
            "\n",
            "🎯 Episode 43: Reward = 76.0, Epsilon = 0.8788\n",
            "🔺 Detected Threat: CVE-2021-21144\n",
            "📝 Description: ['Heap buffer overflow in Tab Groups in Google Chrome prior to 88.0.4324.146 allowed an attacker who convinced a user to install a malicious extension to potentially exploit heap corruption via a crafted Chrome Extension.']\n",
            "\n",
            "🎯 Episode 44: Reward = 121.0, Epsilon = 0.8762\n",
            "🔺 Detected Threat: CVE-2021-31457\n",
            "📝 Description: ['This vulnerability allows remote attackers to execute arbitrary code on affected installations of Foxit Reader 10.1.1.37576. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the handling of Annotation objects. The issue results from the lack of validating the existence of an object prior to performing operations on the object. An attacker can leverage this vulnerability to execute code in the context of the current process. Was ZDI-CAN-13147.']\n",
            "\n",
            "🎯 Episode 45: Reward = 86.0, Epsilon = 0.8735\n",
            "🔺 Detected Threat: CVE-2021-1480\n",
            "📝 Description: ['Multiple vulnerabilities in Cisco SD-WAN vManage Software could allow an unauthenticated, remote attacker to execute arbitrary code or allow an authenticated, local attacker to gain escalated privileges on an affected system. For more information about these vulnerabilities, see the Details section of this advisory.']\n",
            "\n",
            "🎯 Episode 46: Reward = 141.0, Epsilon = 0.8709\n",
            "🔺 Detected Threat: CVE-2021-23042\n",
            "📝 Description: ['On BIG-IP version 16.0.x before 16.0.1.2, 15.1.x before 15.1.3, 14.1.x before 14.1.4, 13.1.x before 13.1.4, and 12.1.x before 12.1.6, when an HTTP profile is configured on a virtual server, undisclosed requests can cause a significant increase in system resource utilization. Note: Software versions which have reached End of Technical Support (EoTS) are not evaluated.']\n",
            "\n",
            "🎯 Episode 47: Reward = 140.0, Epsilon = 0.8683\n",
            "🔺 Detected Threat: CVE-2021-32607\n",
            "📝 Description: ['An issue was discovered in Smartstore (aka SmartStoreNET) through 4.1.1. Views/PrivateMessages/View.cshtml does not call HtmlUtils.SanitizeHtml on a private message.']\n",
            "\n",
            "🎯 Episode 48: Reward = 52.0, Epsilon = 0.8657\n",
            "🔺 Detected Threat: CVE-2021-33910\n",
            "📝 Description: ['basic/unit-name.c in systemd prior to 246.15, 247.8, 248.5, and 249.1 has a Memory Allocation with an Excessive Size Value (involving strdupa and alloca for a pathname controlled by a local attacker) that results in an operating system crash.']\n",
            "\n",
            "🎯 Episode 49: Reward = 132.0, Epsilon = 0.8631\n",
            "🔺 Detected Threat: CVE-2021-28604\n",
            "📝 Description: ['Adobe After Effects version 18.2 (and earlier) is affected by a Heap-based Buffer Overflow vulnerability when parsing a specially crafted file. An unauthenticated attacker could leverage this vulnerability to achieve arbitrary code execution in the context of the current user. Exploitation of this issue requires user interaction in that a victim must open a malicious file.']\n",
            "\n",
            "🎯 Episode 50: Reward = 112.0, Epsilon = 0.8605\n",
            "🔺 Detected Threat: CVE-2021-20775\n",
            "📝 Description: ['Improper input validation vulnerability in Bulletin of Cybozu Garoon 4.10.0 to 5.5.0 allows a remote authenticated attacker to obtain the data of Comment and Space without the viewing privilege.']\n",
            "\n",
            "🎯 Episode 51: Reward = 109.0, Epsilon = 0.8579\n",
            "🔺 Detected Threat: CVE-2021-27550\n",
            "📝 Description: ['Polaris Office v9.102.66 is affected by a divide-by-zero error in PolarisOffice.exe and EngineDLL.dll that may cause a local denial of service. To exploit the vulnerability, someone must open a crafted PDF file.']\n",
            "\n",
            "🎯 Episode 52: Reward = 147.0, Epsilon = 0.8554\n",
            "🔺 Detected Threat: CVE-2021-28100\n",
            "📝 Description: ['Priam uses File.createTempFile, which gives the permissions on that file -rw-r--r--. An attacker with read access to the local filesystem can read anything written there by the Priam process.']\n",
            "\n",
            "🎯 Episode 53: Reward = 125.0, Epsilon = 0.8528\n",
            "🔺 Detected Threat: CVE-2021-20657\n",
            "📝 Description: ['Improper access control vulnerability in SolarView Compact SV-CPT-MC310 prior to Ver.6.5 allows an authenticated attacker to obtain and/or alter the setting information without the access privilege via unspecified vectors.']\n",
            "\n",
            "🎯 Episode 54: Reward = -47.0, Epsilon = 0.8502\n",
            "🔺 Detected Threat: CVE-2021-28565\n",
            "📝 Description: ['Acrobat Reader DC versions versions 2021.001.20150 (and earlier), 2020.001.30020 (and earlier) and 2017.011.30194 (and earlier) are affected by an Out-of-bounds Read vulnerability in the PDFLibTool component. An unauthenticated attacker could leverage this vulnerability to achieve arbitrary code execution in the context of the current user. Exploitation of this issue requires user interaction in that a victim must open a malicious file.']\n",
            "\n",
            "🎯 Episode 55: Reward = 60.0, Epsilon = 0.8477\n",
            "🔺 Detected Threat: CVE-2021-1331\n",
            "📝 Description: ['Multiple vulnerabilities in the web-based management interface of Cisco Small Business RV016, RV042, RV042G, RV082, RV320, and RV325 Routers could allow an authenticated, remote attacker to execute arbitrary code or cause an affected device to restart unexpectedly. These vulnerabilities are due to improper validation of user-supplied input in the web-based management interface. An attacker could exploit these vulnerabilities by sending crafted HTTP requests to an affected device. A successful exploit could allow the attacker to execute arbitrary code as the root user on the underlying operating system or cause the device to reload, resulting in a denial of service (DoS) condition. To exploit these vulnerabilities, an attacker would need to have valid administrator credentials on the affected device.']\n",
            "\n",
            "🎯 Episode 56: Reward = 25.0, Epsilon = 0.8451\n",
            "🔺 Detected Threat: CVE-2021-34722\n",
            "📝 Description: ['Multiple vulnerabilities in the CLI of Cisco IOS XR Software could allow an authenticated, local attacker to gain access to the underlying root shell of an affected device and execute arbitrary commands with root privileges. For more information about these vulnerabilities, see the Details section of this advisory.']\n",
            "\n",
            "🎯 Episode 57: Reward = 64.0, Epsilon = 0.8426\n",
            "🔺 Detected Threat: CVE-2021-25662\n",
            "📝 Description: ['A vulnerability has been identified in SIMATIC HMI Comfort Outdoor Panels V15 7\\\\\" & 15\\\\\" (incl. SIPLUS variants) (All versions < V15 SP1 Update 6), SIMATIC HMI Comfort Outdoor Panels V16 7\\\\\" & 15\\\\\" (incl. SIPLUS variants) (All versions < V16 Update 4), SIMATIC HMI Comfort Panels V15 4\\\\\" - 22\\\\\" (incl. SIPLUS variants) (All versions < V15 SP1 Update 6), SIMATIC HMI Comfort Panels V16 4\\\\\" - 22\\\\\" (incl. SIPLUS variants) (All versions < V16 Update 4), SIMATIC HMI KTP Mobile Panels V15 KTP400F, KTP700, KTP700F, KTP900 and KTP900F (All versions < V15 SP1 Update 6), SIMATIC HMI KTP Mobile Panels V16 KTP400F, KTP700, KTP700F, KTP900 and KTP900F (All versions < V16 Update 4), SIMATIC WinCC Runtime Advanced V15 (All versions < V15 SP1 Update 6), SIMATIC WinCC Runtime Advanced V16 (All versions < V16 Update 4). SmartVNC client fails to handle an exception properly if the program execution process is modified after sending a packet from the server, which could result in a Denial-of-Service condition.']\n",
            "\n",
            "🎯 Episode 58: Reward = 76.0, Epsilon = 0.8401\n",
            "🔺 Detected Threat: CVE-2021-36050\n",
            "📝 Description: ['XMP Toolkit SDK version 2020.1 (and earlier) is affected by a buffer overflow vulnerability potentially resulting in arbitrary code execution in the context of the current user. Exploitation requires user interaction in that a victim must open a crafted file.']\n",
            "\n",
            "🎯 Episode 59: Reward = 128.0, Epsilon = 0.8376\n",
            "🔺 Detected Threat: CVE-2021-37538\n",
            "📝 Description: ['Multiple SQL injection vulnerabilities in SmartDataSoft SmartBlog for PrestaShop before 4.06 allow a remote unauthenticated attacker to execute arbitrary SQL commands via the day, month, or year parameter to the controllers/front/archive.php archive controller, or the id_category parameter to the controllers/front/category.php category controller.']\n",
            "\n",
            "🎯 Episode 60: Reward = 121.0, Epsilon = 0.8350\n",
            "🔺 Detected Threat: CVE-2021-30180\n",
            "📝 Description: ['Apache Dubbo prior to 2.7.9 support Tag routing which will enable a customer to route the request to the right server. These rules are used by the customers when making a request in order to find the right endpoint. When parsing these YAML rules, Dubbo customers may enable calling arbitrary constructors.']\n",
            "\n",
            "🎯 Episode 61: Reward = 19.0, Epsilon = 0.8325\n",
            "🔺 Detected Threat: CVE-2021-23431\n",
            "📝 Description: ['The package joplin before 2.3.2 are vulnerable to Cross-site Request Forgery (CSRF) due to missing CSRF checks in various forms.']\n",
            "\n",
            "🎯 Episode 62: Reward = 163.0, Epsilon = 0.8300\n",
            "🔺 Detected Threat: CVE-2021-30461\n",
            "📝 Description: ['A remote code execution issue was discovered in the web UI of VoIPmonitor before 24.61. When the recheck option is used, the user-supplied SPOOLDIR value (which might contain PHP code) is injected into config/configuration.php.']\n",
            "\n",
            "🎯 Episode 63: Reward = 91.0, Epsilon = 0.8276\n",
            "🔺 Detected Threat: CVE-2021-25200\n",
            "📝 Description: ['Arbitrary file upload vulnerability in SourceCodester Learning Management System v 1.0 allows attackers to execute arbitrary code, via the file upload to \\\\lms\\\\student_avatar.php.']\n",
            "\n",
            "🎯 Episode 64: Reward = 8.0, Epsilon = 0.8251\n",
            "🔺 Detected Threat: CVE-2021-36792\n",
            "📝 Description: ['The dated_news (aka Dated News) extension through 5.1.1 for TYPO3 has incorrect Access Control for confirming various applications.']\n",
            "\n",
            "🎯 Episode 65: Reward = 53.0, Epsilon = 0.8226\n",
            "🔺 Detected Threat: CVE-2021-1429\n",
            "📝 Description: ['Multiple vulnerabilities in the install, uninstall, and upgrade processes of Cisco AnyConnect Secure Mobility Client for Windows could allow an authenticated, local attacker to hijack DLL or executable files that are used by the application. A successful exploit could allow the attacker to execute arbitrary code on an affected device with SYSTEM privileges. To exploit these vulnerabilities, the attacker must have valid credentials on the Windows system. For more information about these vulnerabilities, see the Details section of this advisory.']\n",
            "\n",
            "🎯 Episode 66: Reward = 15.0, Epsilon = 0.8201\n",
            "🔺 Detected Threat: CVE-2021-37646\n",
            "📝 Description: ['TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.StringNGrams` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/string_ngrams_op.cc#L184) calls `reserve` on a `tstring` with a value that sometimes can be negative if user supplies negative `ngram_widths`. The `reserve` method calls `TF_TString_Reserve` which has an `unsigned long` argument for the size of the buffer. Hence, the implicit conversion transforms the negative value to a large integer. We have patched the issue in GitHub commit c283e542a3f422420cfdb332414543b62fc4e4a5. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.']\n",
            "\n",
            "🎯 Episode 67: Reward = 148.0, Epsilon = 0.8177\n",
            "🔺 Detected Threat: CVE-2021-21341\n",
            "📝 Description: [\"XStream is a Java library to serialize objects to XML and back again. In XStream before version 1.4.16, there is vulnerability which may allow a remote attacker to allocate 100% CPU time on the target system depending on CPU type or parallel execution of such a payload resulting in a denial of service only by manipulating the processed input stream. No user is affected who followed the recommendation to setup XStream's security framework with a whitelist limited to the minimal required types. If you rely on XStream's default blacklist of the Security Framework, you will have to use at least version 1.4.16.\"]\n",
            "\n",
            "🎯 Episode 68: Reward = 102.0, Epsilon = 0.8152\n",
            "🔺 Detected Threat: CVE-2021-25420\n",
            "📝 Description: ['Improper log management vulnerability in Galaxy Watch PlugIn prior to version 2.2.05.21033151 allows attacker with log permissions to leak Wi-Fi password connected to the user smartphone within log.']\n",
            "\n",
            "🎯 Episode 69: Reward = 105.0, Epsilon = 0.8128\n",
            "🔺 Detected Threat: CVE-2021-20080\n",
            "📝 Description: ['Insufficient output sanitization in ManageEngine ServiceDesk Plus before version 11200 and ManageEngine AssetExplorer before version 6800 allows a remote, unauthenticated attacker to conduct persistent cross-site scripting (XSS) attacks by uploading a crafted XML asset file.']\n",
            "\n",
            "🎯 Episode 70: Reward = 145.0, Epsilon = 0.8103\n",
            "🔺 Detected Threat: CVE-2021-27412\n",
            "📝 Description: ['Delta Electronics DOPSoft Versions 4.0.10.17 and prior are vulnerable to an out-of-bounds read, which may allow an attacker to execute arbitrary code.']\n",
            "\n",
            "🎯 Episode 71: Reward = 117.0, Epsilon = 0.8079\n",
            "🔺 Detected Threat: CVE-2021-21134\n",
            "📝 Description: ['Incorrect security UI in Page Info in Google Chrome on iOS prior to 88.0.4324.96 allowed a remote attacker to spoof security UI via a crafted HTML page.']\n",
            "\n",
            "🎯 Episode 72: Reward = 28.0, Epsilon = 0.8055\n",
            "🔺 Detected Threat: CVE-2021-1849\n",
            "📝 Description: ['An issue in code signature validation was addressed with improved checks. This issue is fixed in macOS Big Sur 11.3, iOS 14.5 and iPadOS 14.5, watchOS 7.4, tvOS 14.5. A malicious application may be able to bypass Privacy preferences.']\n",
            "\n",
            "🎯 Episode 73: Reward = 104.0, Epsilon = 0.8031\n",
            "🔺 Detected Threat: CVE-2021-31450\n",
            "📝 Description: ['This vulnerability allows remote attackers to execute arbitrary code on affected installations of Foxit Reader 10.1.1.37576. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file. The specific flaw exists within the handling of XFA forms. The issue results from the lack of validating the existence of an object prior to performing operations on the object. An attacker can leverage this vulnerability to execute code in the context of the current process. Was ZDI-CAN-13084.']\n",
            "\n",
            "🎯 Episode 74: Reward = 60.0, Epsilon = 0.8006\n",
            "🔺 Detected Threat: CVE-2021-21028\n",
            "📝 Description: ['Acrobat Reader DC versions versions 2020.013.20074 (and earlier), 2020.001.30018 (and earlier) and 2017.011.30188 (and earlier) are affected by a Use After Free vulnerability. An unauthenticated attacker could leverage this vulnerability to achieve arbitrary code execution in the context of the current user. Exploitation of this issue requires user interaction in that a victim must open a malicious file.']\n",
            "\n",
            "🎯 Episode 75: Reward = 70.0, Epsilon = 0.7982\n",
            "🔺 Detected Threat: CVE-2021-26799\n",
            "📝 Description: ['Cross Site Scripting (XSS) vulnerability in admin/files/edit in Omeka Classic <=2.7 allows remote attackers to inject arbitrary web script or HTML.']\n",
            "\n",
            "🎯 Episode 76: Reward = 50.0, Epsilon = 0.7959\n",
            "🔺 Detected Threat: CVE-2021-38755\n",
            "📝 Description: ['Unauthenticated doctor entry deletion in Hospital Management System in admin-panel1.php.']\n",
            "\n",
            "🎯 Episode 77: Reward = 95.0, Epsilon = 0.7935\n",
            "🔺 Detected Threat: CVE-2021-27573\n",
            "📝 Description: ['An issue was discovered in Emote Remote Mouse through 4.0.0.0. Remote unauthenticated users can execute arbitrary code via crafted UDP packets with no prior authorization or authentication.']\n",
            "\n",
            "🎯 Episode 78: Reward = -87.0, Epsilon = 0.7911\n",
            "🔺 Detected Threat: CVE-2021-22301\n",
            "📝 Description: ['Mate 30 10.0.0.203(C00E201R7P2) have a buffer overflow vulnerability. After obtaining the root permission, an attacker can exploit the vulnerability to cause buffer overflow.']\n",
            "\n",
            "🎯 Episode 79: Reward = 113.0, Epsilon = 0.7887\n",
            "🔺 Detected Threat: CVE-2021-22524\n",
            "📝 Description: ['Injection attack caused the denial of service vulnerability in NetIQ Access Manager prior to 5.0.1 and 4.5.4']\n",
            "\n",
            "🎯 Episode 80: Reward = 149.0, Epsilon = 0.7863\n",
            "🔺 Detected Threat: CVE-2021-30473\n",
            "📝 Description: ['aom_image.c in libaom in AOMedia before 2021-04-07 frees memory that is not located on the heap.']\n",
            "\n",
            "🎯 Episode 81: Reward = 59.0, Epsilon = 0.7840\n",
            "🔺 Detected Threat: CVE-2021-29518\n",
            "📝 Description: ['TensorFlow is an end-to-end open source platform for machine learning. In eager mode (default in TF 2.0 and later), session operations are invalid. However, users could still call the raw ops associated with them and trigger a null pointer dereference. The implementation(https://github.com/tensorflow/tensorflow/blob/eebb96c2830d48597d055d247c0e9aebaea94cd5/tensorflow/core/kernels/session_ops.cc#L104) dereferences the session state pointer without checking if it is valid. Thus, in eager mode, `ctx->session_state()` is nullptr and the call of the member function is undefined behavior. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.']\n",
            "\n",
            "🎯 Episode 82: Reward = -27.0, Epsilon = 0.7816\n",
            "🔺 Detected Threat: CVE-2021-27053\n",
            "📝 Description: ['Microsoft Excel Remote Code Execution Vulnerability This CVE ID is unique from CVE-2021-27054.']\n",
            "\n",
            "🎯 Episode 83: Reward = 45.0, Epsilon = 0.7793\n",
            "🔺 Detected Threat: CVE-2021-1756\n",
            "📝 Description: ['A lock screen issue allowed access to contacts on a locked device. This issue was addressed with improved state management. This issue is fixed in iOS 14.4 and iPadOS 14.4. An attacker with physical access to a device may be able to see private contact information.']\n",
            "\n",
            "🎯 Episode 84: Reward = 41.0, Epsilon = 0.7770\n",
            "🔺 Detected Threat: CVE-2021-37788\n",
            "📝 Description: ['A vulnerability in the web UI of Gurock TestRail v5.3.0.3603 could allow an unauthenticated, remote attacker to affect the integrity of a device via a clickjacking attack. The vulnerability is due to insufficient input validation of iFrame data in HTTP requests that are sent to an affected device. An attacker could exploit this vulnerability by sending crafted HTTP packets with malicious iFrame data. A successful exploit could allow the attacker to perform a clickjacking attack where the user is tricked into clicking a malicious link.']\n",
            "\n",
            "🎯 Episode 85: Reward = 143.0, Epsilon = 0.7746\n",
            "🔺 Detected Threat: CVE-2021-22742\n",
            "📝 Description: ['Improper Check for Unusual or Exceptional Conditions vulnerability exists in Triconex Model 3009 MP installed on Tricon V11.3.x systems that could cause module reset when TCM receives malformed TriStation packets while the write-protect keyswitch is in the program position.']\n",
            "\n",
            "🎯 Episode 86: Reward = 132.0, Epsilon = 0.7723\n",
            "🔺 Detected Threat: CVE-2021-25239\n",
            "📝 Description: ['An improper access control vulnerability in Trend Micro Apex One (on-prem), OfficeScan XG SP1, and Worry-Free Business Security 10.0 SP1 could allow an unauthenticated user to obtain information about x86 agent hotfixes.']\n",
            "\n",
            "🎯 Episode 87: Reward = 16.0, Epsilon = 0.7700\n",
            "🔺 Detected Threat: CVE-2021-30961\n",
            "📝 Description: ['** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: none. Reason: This candidate was withdrawn by the CVE program. Notes: none.']\n",
            "\n",
            "🎯 Episode 88: Reward = 146.0, Epsilon = 0.7677\n",
            "🔺 Detected Threat: CVE-2021-1829\n",
            "📝 Description: ['A type confusion issue was addressed with improved state handling. This issue is fixed in macOS Big Sur 11.3. An application may be able to execute arbitrary code with kernel privileges.']\n",
            "\n",
            "🎯 Episode 89: Reward = 85.0, Epsilon = 0.7654\n",
            "🔺 Detected Threat: CVE-2021-30966\n",
            "📝 Description: ['** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: none. Reason: This candidate was withdrawn by the CVE program. Notes: none.']\n",
            "\n",
            "🎯 Episode 90: Reward = 110.0, Epsilon = 0.7631\n",
            "🔺 Detected Threat: CVE-2021-30939\n",
            "📝 Description: ['** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: none. Reason: This candidate was withdrawn by the CVE program. Notes: none.']\n",
            "\n",
            "🎯 Episode 91: Reward = 26.0, Epsilon = 0.7608\n",
            "🔺 Detected Threat: CVE-2021-34659\n",
            "📝 Description: ['The Plugmatter Pricing Table Lite WordPress plugin is vulnerable to Reflected Cross-Site Scripting via the `email` parameter in the ~/license.php file which allows attackers to inject arbitrary web scripts, in versions up to and including 1.0.32.']\n",
            "\n",
            "🎯 Episode 92: Reward = 69.0, Epsilon = 0.7585\n",
            "🔺 Detected Threat: CVE-2021-21220\n",
            "📝 Description: ['Insufficient validation of untrusted input in V8 in Google Chrome prior to 89.0.4389.128 allowed a remote attacker to potentially exploit heap corruption via a crafted HTML page.']\n",
            "\n",
            "🎯 Episode 93: Reward = 24.0, Epsilon = 0.7562\n",
            "🔺 Detected Threat: CVE-2021-2430\n",
            "📝 Description: ['Vulnerability in the Oracle Outside In Technology product of Oracle Fusion Middleware (component: Outside In Filters). The supported version that is affected is 8.5.5. Easily exploitable vulnerability allows unauthenticated attacker with network access via HTTP to compromise Oracle Outside In Technology. Successful attacks of this vulnerability can result in unauthorized ability to cause a hang or frequently repeatable crash (complete DOS) of Oracle Outside In Technology. Note: Outside In Technology is a suite of software development kits (SDKs). The protocol and CVSS Base Score depend on the software that uses Outside In Technology. The CVSS score assumes that the software passes data received over a network directly to Outside In Technology, but if data is not received over a network the CVSS score may be lower. CVSS 3.1 Base Score 7.5 (Availability impacts). CVSS Vector: (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H).']\n",
            "\n",
            "🎯 Episode 94: Reward = 23.0, Epsilon = 0.7540\n",
            "🔺 Detected Threat: CVE-2021-24593\n",
            "📝 Description: ['The Business Hours Indicator WordPress plugin before 2.3.5 does not sanitise or escape its \\'Now closed message\" setting when outputting it in the backend and frontend, leading to an Authenticated Stored Cross-Site Scripting issue']\n",
            "\n",
            "🎯 Episode 95: Reward = 25.0, Epsilon = 0.7517\n",
            "🔺 Detected Threat: CVE-2021-26273\n",
            "📝 Description: ['The Agent in NinjaRMM 5.0.909 has Incorrect Access Control.']\n",
            "\n",
            "🎯 Episode 96: Reward = 89.0, Epsilon = 0.7494\n",
            "🔺 Detected Threat: CVE-2021-31116\n",
            "📝 Description: ['** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. ConsultIDs: none. Reason: This candidate was withdrawn by the CVE program. Notes: none.']\n",
            "\n",
            "🎯 Episode 97: Reward = 145.0, Epsilon = 0.7472\n",
            "🔺 Detected Threat: CVE-2021-32766\n",
            "📝 Description: ['Nextcloud Text is an open source plaintext editing application which ships with the nextcloud server. In affected versions the Nextcloud Text application returned different error messages depending on whether a folder existed in a public link share. This is problematic in case the public link share has been created with \"Upload Only\" privileges. (aka \"File Drop\"). A link share recipient is not expected to see which folders or files exist in a \"File Drop\" share. Using this vulnerability an attacker is able to enumerate folders in such a share. Exploitation requires that the attacker has access to a valid affected \"File Drop\" link share. It is recommended that the Nextcloud Server is upgraded to 20.0.12, 21.0.4 or 22.0.1. Users who are unable to upgrade are advised to disable the Nextcloud Text application in the app settings.']\n",
            "\n",
            "🎯 Episode 98: Reward = 134.0, Epsilon = 0.7449\n",
            "🔺 Detected Threat: CVE-2021-34481\n",
            "📝 Description: ['Windows Print Spooler Elevation of Privilege Vulnerability']\n",
            "\n",
            "🎯 Episode 99: Reward = 69.0, Epsilon = 0.7427\n",
            "🔺 Detected Threat: CVE-2021-1699\n",
            "📝 Description: ['Windows (modem.sys) Information Disclosure Vulnerability']\n",
            "\n",
            "✅ Simulation Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8:56\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# ====================================\n",
        "#  1️⃣ NEO4J CONFIGURATION & DATA FETCHING\n",
        "# ====================================\n",
        "\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:13454\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "class Neo4jConnector:\n",
        "    \"\"\"Handles interaction with Neo4j database for retrieving threat details.\"\"\"\n",
        "\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self):\n",
        "        \"\"\"Retrieve attack threats from the Neo4j database.\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC)\n",
        "        RETURN capec.ID AS CAPEC_ID, capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return {record[\"CAPEC_ID\"]: record.data() for record in result}\n",
        "\n",
        "    def get_threat_by_id(self, threat_id):\n",
        "        \"\"\"Retrieve attack details for a given threat ID.\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC {ID: $threat_id})\n",
        "        RETURN capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, threat_id=threat_id)\n",
        "            return result.single()\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "\n",
        "# ✅ Filter Allowed Threats\n",
        "allowed_attack_ids = [\"CVE-2021-0109\", \"CVE-2021-0259\", \"CVE-2021-0102\"]\n",
        "valid_threats = [tid for tid in allowed_attack_ids if tid in attack_data]\n",
        "num_threats = max(1, len(valid_threats))\n",
        "\n",
        "print(f\"✅ Valid Threats: {valid_threats}\")\n",
        "\n",
        "# ====================================\n",
        "#  2️⃣ DQN MODEL\n",
        "# ====================================\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \"\"\"Deep Q-Network (DQN) for learning attack strategies and detecting threats.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "        self.threat_layer = nn.Linear(128, num_threats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# ====================================\n",
        "#  3️⃣ EXPERIENCE REPLAY BUFFER\n",
        "# ====================================\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Experience Replay Buffer for storing past transitions.\"\"\"\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# ====================================\n",
        "#  4️⃣ ACTION SELECTION (EPSILON-GREEDY)\n",
        "# ====================================\n",
        "\n",
        "def select_action(state, epsilon):\n",
        "    \"\"\"Epsilon-Greedy Policy for selecting integer actions.\"\"\"\n",
        "    if random.random() < epsilon:  # Explore\n",
        "        return int(env.action_space.sample())  # Ensure integer return\n",
        "    else:  # Exploit\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        q_values, _ = policy_net(state_tensor)\n",
        "        return int(torch.argmax(q_values).item())  # Ensure integer return\n",
        "\n",
        "def get_attack_type(action):\n",
        "    \"\"\"Map NASim action index to attack type.\"\"\"\n",
        "    if isinstance(action, int) and action < len(env.action_space.actions):\n",
        "        return env.action_space.actions[action].__str__()  # Convert action to string\n",
        "    return \"Unknown Action\"\n",
        "\n",
        "# ====================================\n",
        "#  5️⃣ TRAINING FUNCTION\n",
        "# ====================================\n",
        "\n",
        "def train_dqn():\n",
        "    \"\"\"Train the DQN using Experience Replay.\"\"\"\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, _ = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor(dones)\n",
        "\n",
        "    q_values, _ = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions).squeeze(1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        next_q_values, _ = target_net(next_states)\n",
        "        max_next_q_values = next_q_values.max(1)[0]\n",
        "\n",
        "    target_q_values = rewards + (GAMMA * max_next_q_values * (1 - dones))\n",
        "\n",
        "    loss = nn.MSELoss()(q_values, target_q_values)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# ====================================\n",
        "#  6️⃣ TRAINING LOOP\n",
        "# ====================================\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# ✅ Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "\n",
        "        # ✅ Get NASim attack type\n",
        "        attack_type = get_attack_type(action)\n",
        "\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        # Predict Threat Type\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "\n",
        "        threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "        threat_details = neo4j_db.get_threat_by_id(threat_type)\n",
        "        threat_description = threat_details[\"CAPEC_Name\"] if threat_details else \"Unknown Threat\"\n",
        "\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "        # ✅ Print Attack Type & Threat\n",
        "        print(f\"Episode {episode} | Action: {attack_type} | Reward: {reward} | Threat: {threat_description}\")\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "    print(f\"🎯 Episode {episode} completed. Total Reward = {total_reward}, Epsilon = {epsilon:.4f}\")\n",
        "\n",
        "# ✅ Save Model & Close DB\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"✅ Simulation Completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z3M4hs5c-AdY",
        "outputId": "c47d8531-d91f-4255-9d20-a0cd3a4f01ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Valid Threats: []\n",
            "Episode 0 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(1, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(1, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(1, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: 99.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: SubnetScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 0 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: 99.0 | Threat: Unknown Threat\n",
            "🎯 Episode 0 completed. Total Reward = 81.0, Epsilon = 0.9970\n",
            "Episode 1 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(1, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(1, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(2, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(1, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(1, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(3, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(3, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ProcessScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: Exploit: target=(3, 0), cost=1.00, prob=0.80, req_access=USER, os=linux, service=ssh, access=1 | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: PrivilegeEscalation: target=(2, 0), cost=1.00, prob=1.00, req_access=USER, os=linux, process=tomcat, access=2 | Reward: -1.0 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: ServiceScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: SubnetScan: target=(1, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n",
            "Episode 1 | Action: OSScan: target=(2, 0), cost=1.00, prob=1.00, req_access=USER | Reward: -1 | Threat: Unknown Threat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a2f2ae543814>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mthreat_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreat_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mthreat_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneo4j_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_threat_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreat_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mthreat_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreat_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CAPEC_Name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthreat_details\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"Unknown Threat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a2f2ae543814>\u001b[0m in \u001b[0;36mget_threat_by_id\u001b[0;34m(self, threat_id)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \"\"\"\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreat_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mbookmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bookmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         self._auto_result._run(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exhausted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNeo4jError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionExpired\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# Receive exactly one message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         tag, fields = self.inbox.pop(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydration_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, hydration_hooks)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_one_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_structure_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36m_buffer_one_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;31m# Determine the chunk size and skip noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mreceive_into_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_u16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mreceive_into_buffer\u001b[0;34m(sock, buffer, n_bytes)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             n = sock.recv_into(\n\u001b[0m\u001b[1;32m    346\u001b[0m                 \u001b[0mview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_async_compat/network/_bolt_socket.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j/_async_compat/network/_bolt_socket.py\u001b[0m in \u001b[0;36m_wait_for_io\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mdeadline_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# ====================================\n",
        "#  1️⃣ NEO4J CONFIGURATION & DATA FETCHING\n",
        "# ====================================\n",
        "\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:13454\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "class Neo4jConnector:\n",
        "    \"\"\"Handles interaction with Neo4j database for retrieving threat details.\"\"\"\n",
        "\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self):\n",
        "        \"\"\"Retrieve attack threats from the Neo4j database.\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC)\n",
        "        RETURN capec.ID AS CAPEC_ID, capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return {record[\"CAPEC_ID\"]: record.data() for record in result}\n",
        "\n",
        "    def get_threat_by_id(self, threat_id):\n",
        "        \"\"\"Retrieve attack details for a given threat ID.\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC {ID: $threat_id})\n",
        "        RETURN capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, threat_id=threat_id)\n",
        "            return result.single()\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "\n",
        "# ✅ Filter Allowed Threats\n",
        "allowed_attack_ids = [\"CVE-2021-0109\", \"CVE-2021-0259\", \"CVE-2021-0102\"]\n",
        "valid_threats = [tid for tid in allowed_attack_ids if tid in attack_data]\n",
        "num_threats = max(1, len(valid_threats))\n",
        "\n",
        "print(f\"✅ Valid Threats: {valid_threats}\")\n",
        "\n",
        "# ====================================\n",
        "#  2️⃣ DQN MODEL\n",
        "# ====================================\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    \"\"\"Deep Q-Network (DQN) for learning attack strategies and detecting threats.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "        self.threat_layer = nn.Linear(128, num_threats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# ====================================\n",
        "#  3️⃣ EXPERIENCE REPLAY BUFFER\n",
        "# ====================================\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Experience Replay Buffer for storing past transitions.\"\"\"\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# ====================================\n",
        "#  4️⃣ ACTION SELECTION (EPSILON-GREEDY)\n",
        "# ====================================\n",
        "\n",
        "def select_action(state, epsilon):\n",
        "    \"\"\"Epsilon-Greedy Policy for selecting integer actions.\"\"\"\n",
        "    if random.random() < epsilon:  # Explore\n",
        "        return int(env.action_space.sample())  # Ensure integer return\n",
        "    else:  # Exploit\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        q_values, _ = policy_net(state_tensor)\n",
        "        return int(torch.argmax(q_values).item())  # Ensure integer return\n",
        "\n",
        "\n",
        "# ====================================\n",
        "#  5️⃣ TRAINING FUNCTION\n",
        "# ====================================\n",
        "\n",
        "def train_dqn():\n",
        "    \"\"\"Train the DQN using Experience Replay.\"\"\"\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, _ = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor(dones)\n",
        "\n",
        "    q_values, _ = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions).squeeze(1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        next_q_values, _ = target_net(next_states)\n",
        "        max_next_q_values = next_q_values.max(1)[0]\n",
        "\n",
        "    target_q_values = rewards + (GAMMA * max_next_q_values * (1 - dones))\n",
        "\n",
        "    loss = nn.MSELoss()(q_values, target_q_values)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# ====================================\n",
        "#  6️⃣ TRAINING LOOP\n",
        "# ====================================\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# ✅ Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "        threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "    print(f\"🎯 Episode {episode}: Reward = {total_reward}, Epsilon = {epsilon:.4f}\")\n",
        "\n",
        "# ✅ Save Model & Close DB\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"✅ Simulation Completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsApg5hg4Fql",
        "outputId": "6186a9a7-ea1a-4071-9729-1643e01b204f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Valid Threats: []\n",
            "🎯 Episode 0: Reward = 116.0, Epsilon = 0.9970\n",
            "🎯 Episode 1: Reward = 101.0, Epsilon = 0.9940\n",
            "🎯 Episode 2: Reward = 159.0, Epsilon = 0.9910\n",
            "🎯 Episode 3: Reward = 72.0, Epsilon = 0.9881\n",
            "🎯 Episode 4: Reward = 95.0, Epsilon = 0.9851\n",
            "🎯 Episode 5: Reward = -33.0, Epsilon = 0.9821\n",
            "🎯 Episode 6: Reward = 108.0, Epsilon = 0.9792\n",
            "🎯 Episode 7: Reward = 121.0, Epsilon = 0.9763\n",
            "🎯 Episode 8: Reward = 151.0, Epsilon = 0.9733\n",
            "🎯 Episode 9: Reward = 114.0, Epsilon = 0.9704\n",
            "🎯 Episode 10: Reward = 106.0, Epsilon = 0.9675\n",
            "🎯 Episode 11: Reward = 48.0, Epsilon = 0.9646\n",
            "🎯 Episode 12: Reward = 122.0, Epsilon = 0.9617\n",
            "🎯 Episode 13: Reward = 117.0, Epsilon = 0.9588\n",
            "🎯 Episode 14: Reward = 58.0, Epsilon = 0.9559\n",
            "🎯 Episode 15: Reward = 96.0, Epsilon = 0.9531\n",
            "🎯 Episode 16: Reward = 84.0, Epsilon = 0.9502\n",
            "🎯 Episode 17: Reward = 80.0, Epsilon = 0.9474\n",
            "🎯 Episode 18: Reward = 136.0, Epsilon = 0.9445\n",
            "🎯 Episode 19: Reward = 138.0, Epsilon = 0.9417\n",
            "🎯 Episode 20: Reward = 148.0, Epsilon = 0.9389\n",
            "🎯 Episode 21: Reward = 135.0, Epsilon = 0.9360\n",
            "🎯 Episode 22: Reward = 127.0, Epsilon = 0.9332\n",
            "🎯 Episode 23: Reward = 86.0, Epsilon = 0.9304\n",
            "🎯 Episode 24: Reward = 107.0, Epsilon = 0.9276\n",
            "🎯 Episode 25: Reward = 89.0, Epsilon = 0.9249\n",
            "🎯 Episode 26: Reward = 144.0, Epsilon = 0.9221\n",
            "🎯 Episode 27: Reward = 97.0, Epsilon = 0.9193\n",
            "🎯 Episode 28: Reward = 93.0, Epsilon = 0.9166\n",
            "🎯 Episode 29: Reward = 146.0, Epsilon = 0.9138\n",
            "🎯 Episode 30: Reward = 161.0, Epsilon = 0.9111\n",
            "🎯 Episode 31: Reward = 91.0, Epsilon = 0.9083\n",
            "🎯 Episode 32: Reward = 144.0, Epsilon = 0.9056\n",
            "🎯 Episode 33: Reward = 85.0, Epsilon = 0.9029\n",
            "🎯 Episode 34: Reward = 81.0, Epsilon = 0.9002\n",
            "🎯 Episode 35: Reward = 72.0, Epsilon = 0.8975\n",
            "🎯 Episode 36: Reward = 158.0, Epsilon = 0.8948\n",
            "🎯 Episode 37: Reward = 60.0, Epsilon = 0.8921\n",
            "🎯 Episode 38: Reward = 65.0, Epsilon = 0.8894\n",
            "🎯 Episode 39: Reward = 69.0, Epsilon = 0.8868\n",
            "🎯 Episode 40: Reward = 91.0, Epsilon = 0.8841\n",
            "🎯 Episode 41: Reward = 152.0, Epsilon = 0.8814\n",
            "🎯 Episode 42: Reward = 71.0, Epsilon = 0.8788\n",
            "🎯 Episode 43: Reward = 130.0, Epsilon = 0.8762\n",
            "🎯 Episode 44: Reward = 148.0, Epsilon = 0.8735\n",
            "🎯 Episode 45: Reward = 66.0, Epsilon = 0.8709\n",
            "🎯 Episode 46: Reward = 124.0, Epsilon = 0.8683\n",
            "🎯 Episode 47: Reward = 173.0, Epsilon = 0.8657\n",
            "🎯 Episode 48: Reward = 114.0, Epsilon = 0.8631\n",
            "🎯 Episode 49: Reward = 109.0, Epsilon = 0.8605\n",
            "🎯 Episode 50: Reward = 54.0, Epsilon = 0.8579\n",
            "🎯 Episode 51: Reward = 16.0, Epsilon = 0.8554\n",
            "🎯 Episode 52: Reward = 74.0, Epsilon = 0.8528\n",
            "🎯 Episode 53: Reward = 130.0, Epsilon = 0.8502\n",
            "🎯 Episode 54: Reward = 119.0, Epsilon = 0.8477\n",
            "🎯 Episode 55: Reward = 119.0, Epsilon = 0.8451\n",
            "🎯 Episode 56: Reward = 117.0, Epsilon = 0.8426\n",
            "🎯 Episode 57: Reward = 100.0, Epsilon = 0.8401\n",
            "🎯 Episode 58: Reward = 119.0, Epsilon = 0.8376\n",
            "🎯 Episode 59: Reward = -50.0, Epsilon = 0.8350\n",
            "🎯 Episode 60: Reward = 126.0, Epsilon = 0.8325\n",
            "🎯 Episode 61: Reward = 172.0, Epsilon = 0.8300\n",
            "🎯 Episode 62: Reward = 75.0, Epsilon = 0.8276\n",
            "🎯 Episode 63: Reward = 59.0, Epsilon = 0.8251\n",
            "🎯 Episode 64: Reward = 148.0, Epsilon = 0.8226\n",
            "🎯 Episode 65: Reward = 171.0, Epsilon = 0.8201\n",
            "🎯 Episode 66: Reward = 165.0, Epsilon = 0.8177\n",
            "🎯 Episode 67: Reward = 17.0, Epsilon = 0.8152\n",
            "🎯 Episode 68: Reward = 160.0, Epsilon = 0.8128\n",
            "🎯 Episode 69: Reward = 152.0, Epsilon = 0.8103\n",
            "🎯 Episode 70: Reward = 61.0, Epsilon = 0.8079\n",
            "🎯 Episode 71: Reward = 70.0, Epsilon = 0.8055\n",
            "🎯 Episode 72: Reward = 1.0, Epsilon = 0.8031\n",
            "🎯 Episode 73: Reward = 127.0, Epsilon = 0.8006\n",
            "🎯 Episode 74: Reward = 128.0, Epsilon = 0.7982\n",
            "🎯 Episode 75: Reward = 61.0, Epsilon = 0.7959\n",
            "🎯 Episode 76: Reward = 86.0, Epsilon = 0.7935\n",
            "🎯 Episode 77: Reward = -5.0, Epsilon = 0.7911\n",
            "🎯 Episode 78: Reward = 55.0, Epsilon = 0.7887\n",
            "🎯 Episode 79: Reward = 106.0, Epsilon = 0.7863\n",
            "🎯 Episode 80: Reward = 113.0, Epsilon = 0.7840\n",
            "🎯 Episode 81: Reward = 57.0, Epsilon = 0.7816\n",
            "🎯 Episode 82: Reward = 63.0, Epsilon = 0.7793\n",
            "🎯 Episode 83: Reward = 130.0, Epsilon = 0.7770\n",
            "🎯 Episode 84: Reward = 162.0, Epsilon = 0.7746\n",
            "🎯 Episode 85: Reward = 102.0, Epsilon = 0.7723\n",
            "🎯 Episode 86: Reward = 59.0, Epsilon = 0.7700\n",
            "🎯 Episode 87: Reward = 60.0, Epsilon = 0.7677\n",
            "🎯 Episode 88: Reward = 111.0, Epsilon = 0.7654\n",
            "🎯 Episode 89: Reward = 108.0, Epsilon = 0.7631\n",
            "🎯 Episode 90: Reward = 91.0, Epsilon = 0.7608\n",
            "🎯 Episode 91: Reward = 125.0, Epsilon = 0.7585\n",
            "🎯 Episode 92: Reward = 127.0, Epsilon = 0.7562\n",
            "🎯 Episode 93: Reward = 67.0, Epsilon = 0.7540\n",
            "🎯 Episode 94: Reward = 119.0, Epsilon = 0.7517\n",
            "🎯 Episode 95: Reward = 106.0, Epsilon = 0.7494\n",
            "🎯 Episode 96: Reward = 114.0, Epsilon = 0.7472\n",
            "🎯 Episode 97: Reward = 119.0, Epsilon = 0.7449\n",
            "🎯 Episode 98: Reward = 70.0, Epsilon = 0.7427\n",
            "🎯 Episode 99: Reward = 116.0, Epsilon = 0.7405\n",
            "✅ Training Completed. Model saved as 'dqn_nasim_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 :45\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j Configuration\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:13454\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "# Connect to Neo4j\n",
        "class Neo4jConnector:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self):\n",
        "        \"\"\"Fetch attack details dynamically from Neo4j\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC)\n",
        "        RETURN capec.ID AS CAPEC_ID, capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return {record[\"CAPEC_ID\"]: record.data() for record in result}  # Return a dictionary {ID: Details}\n",
        "\n",
        "    def get_threat_by_id(self, threat_id):\n",
        "        \"\"\"Fetch attack details for a given CAPEC_ID\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC {ID: $threat_id})\n",
        "        RETURN capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, threat_id=threat_id)\n",
        "            return result.single()  # Return single record\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "\n",
        "# ✅ Provide a list of valid attack IDs from Neo4j (Example: Only allow certain threats)\n",
        "allowed_attack_ids = [\"CVE-2021-0109\", \"CVE-2021-0259\", \"CVE-2021-0102\"]\n",
        "filtered_attack_data = {key: attack_data[key] for key in allowed_attack_ids if key in attack_data}\n",
        "\n",
        "# Extract Known Threats\n",
        "valid_threats = list(filtered_attack_data.keys())  # Only keep valid threat IDs\n",
        "num_threats = max(1, len(valid_threats))\n",
        "\n",
        "print(f\"Valid Threat IDs: {valid_threats}\")\n",
        "print(f\"Number of Known Threat Categories: {num_threats}\")\n",
        "\n",
        "# Threat Mapping\n",
        "def map_threat_id(index):\n",
        "    \"\"\"Maps predicted index to allowed CAPEC_ID\"\"\"\n",
        "    if 0 <= index < len(valid_threats):\n",
        "        return valid_threats[index]\n",
        "    return None  # If invalid, return None\n",
        "\n",
        "# ✅ NASim Attack Mapping\n",
        "def get_attack_type(action_index):\n",
        "    \"\"\"Returns a human-readable attack type for a given NASim action index\"\"\"\n",
        "    action = env.action_space.get_action(action_index)\n",
        "  # Retrieve action details\n",
        "\n",
        "    if action.is_scan():\n",
        "        return \"Scan Attack\"\n",
        "    elif action.is_exploit():\n",
        "        return f\"Exploit Attack (Vulnerability: {action.name})\"\n",
        "    elif action.is_privilege_escalation():\n",
        "        return \"Privilege Escalation Attack\"\n",
        "    else:\n",
        "        return \"Unknown Attack\"\n",
        "\n",
        "# Define DQN Model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "        self.threat_layer = nn.Linear(128, num_threats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# Experience Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    state = np.zeros(state_dim) if state is None or len(state) == 0 else state\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        attack_type = get_attack_type(action)  # ✅ Get NASim attack name\n",
        "        next_state, reward, done, _, info = env.step(action)\n",
        "        next_state = np.zeros(state_dim) if next_state is None or len(next_state) == 0 else next_state\n",
        "\n",
        "        # Predict Threat Type\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "\n",
        "        # Ensure detected threats match only the allowed threat IDs\n",
        "        threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "        threat_id = map_threat_id(threat_type)\n",
        "\n",
        "        # Query Neo4j for threat details\n",
        "        if threat_id:\n",
        "            threat_details = neo4j_db.get_threat_by_id(threat_id)\n",
        "            threat_description = threat_details[\"CAPEC_Name\"] if threat_details else \"Unknown Threat\"\n",
        "        else:\n",
        "            threat_description = \"No Threat Detected\"\n",
        "\n",
        "        # Store experience\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "        # ✅ Print Attack Type + Detected Threat\n",
        "        print(f\"Episode {episode} | Reward: {reward}\")\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    # Update Target Network\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "    print(f\"Episode {episode} completed. Total Reward = {total_reward}, Epsilon = {epsilon:.4f} Action: {attack_type} \")\n",
        "\n",
        "# Save Model\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"Simulation complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uEiEfXYtF0y7",
        "outputId": "1919f977-72ce-4553-91a1-23d449affcdb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Threat IDs: []\n",
            "Number of Known Threat Categories: 1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: 99.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1.0\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: -1\n",
            "Episode 0 | Reward: 99.0\n",
            "Episode 0 completed. Total Reward = 80.0, Epsilon = 0.9970 Action: Privilege Escalation Attack \n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: 99.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1.0\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: -1\n",
            "Episode 1 | Reward: 99.0\n",
            "Episode 1 completed. Total Reward = 74.0, Epsilon = 0.9940 Action: Privilege Escalation Attack \n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: 99.0\n",
            "Episode 2 | Reward: -1\n",
            "Episode 2 | Reward: -1.0\n",
            "Episode 2 | Reward: 99.0\n",
            "Episode 2 completed. Total Reward = 159.0, Epsilon = 0.9910 Action: Privilege Escalation Attack \n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: 99.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1.0\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: -1\n",
            "Episode 3 | Reward: 99.0\n",
            "Episode 3 completed. Total Reward = 90.0, Epsilon = 0.9881 Action: Privilege Escalation Attack \n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: 99.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1\n",
            "Episode 4 | Reward: -1.0\n",
            "Episode 4 | Reward: 99.0\n",
            "Episode 4 completed. Total Reward = 48.0, Epsilon = 0.9851 Action: Privilege Escalation Attack \n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: 99.0\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: -1\n",
            "Episode 5 | Reward: 99.0\n",
            "Episode 5 completed. Total Reward = 104.0, Epsilon = 0.9821 Action: Privilege Escalation Attack \n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: 99.0\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: -1\n",
            "Episode 6 | Reward: 99.0\n",
            "Episode 6 completed. Total Reward = 83.0, Epsilon = 0.9792 Action: Privilege Escalation Attack \n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: 99.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: -1.0\n",
            "Episode 7 | Reward: -1\n",
            "Episode 7 | Reward: 99.0\n",
            "Episode 7 completed. Total Reward = 78.0, Epsilon = 0.9763 Action: Privilege Escalation Attack \n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: 99.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1.0\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: -1\n",
            "Episode 8 | Reward: 99.0\n",
            "Episode 8 completed. Total Reward = 153.0, Epsilon = 0.9733 Action: Privilege Escalation Attack \n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: 99.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1.0\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: -1\n",
            "Episode 9 | Reward: 99.0\n",
            "Episode 9 completed. Total Reward = 16.0, Epsilon = 0.9704 Action: Privilege Escalation Attack \n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: 99.0\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1.0\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: -1\n",
            "Episode 10 | Reward: 99.0\n",
            "Episode 10 completed. Total Reward = 119.0, Epsilon = 0.9675 Action: Privilege Escalation Attack \n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: 99.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: -1.0\n",
            "Episode 11 | Reward: -1\n",
            "Episode 11 | Reward: 99.0\n",
            "Episode 11 completed. Total Reward = 31.0, Epsilon = 0.9646 Action: Privilege Escalation Attack \n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: 99.0\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1.0\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: -1\n",
            "Episode 12 | Reward: 99.0\n",
            "Episode 12 completed. Total Reward = 149.0, Epsilon = 0.9617 Action: Privilege Escalation Attack \n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: 99.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1.0\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: -1\n",
            "Episode 13 | Reward: 99.0\n",
            "Episode 13 completed. Total Reward = 101.0, Epsilon = 0.9588 Action: Privilege Escalation Attack \n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: 99.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1.0\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: -1\n",
            "Episode 14 | Reward: 99.0\n",
            "Episode 14 completed. Total Reward = 131.0, Epsilon = 0.9559 Action: Privilege Escalation Attack \n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: 99.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1\n",
            "Episode 15 | Reward: -1.0\n",
            "Episode 15 | Reward: 99.0\n",
            "Episode 15 completed. Total Reward = 101.0, Epsilon = 0.9531 Action: Privilege Escalation Attack \n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: 99.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1.0\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: -1\n",
            "Episode 16 | Reward: 99.0\n",
            "Episode 16 completed. Total Reward = 32.0, Epsilon = 0.9502 Action: Privilege Escalation Attack \n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: 99.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1.0\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: -1\n",
            "Episode 17 | Reward: 99.0\n",
            "Episode 17 completed. Total Reward = 137.0, Epsilon = 0.9474 Action: Privilege Escalation Attack \n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: 99.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1.0\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: -1\n",
            "Episode 18 | Reward: 99.0\n",
            "Episode 18 completed. Total Reward = 83.0, Epsilon = 0.9445 Action: Privilege Escalation Attack \n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: 99.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1.0\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: -1\n",
            "Episode 19 | Reward: 99.0\n",
            "Episode 19 completed. Total Reward = 145.0, Epsilon = 0.9417 Action: Privilege Escalation Attack \n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: 99.0\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1.0\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: -1\n",
            "Episode 20 | Reward: 99.0\n",
            "Episode 20 completed. Total Reward = 109.0, Epsilon = 0.9389 Action: Privilege Escalation Attack \n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: 99.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1\n",
            "Episode 21 | Reward: -1.0\n",
            "Episode 21 | Reward: 99.0\n",
            "Episode 21 completed. Total Reward = 169.0, Epsilon = 0.9360 Action: Privilege Escalation Attack \n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: 99.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1.0\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: -1\n",
            "Episode 22 | Reward: 99.0\n",
            "Episode 22 completed. Total Reward = 33.0, Epsilon = 0.9332 Action: Privilege Escalation Attack \n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: 99.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1.0\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: -1\n",
            "Episode 23 | Reward: 99.0\n",
            "Episode 23 completed. Total Reward = 81.0, Epsilon = 0.9304 Action: Privilege Escalation Attack \n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: 99.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1.0\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: -1\n",
            "Episode 24 | Reward: 99.0\n",
            "Episode 24 completed. Total Reward = 83.0, Epsilon = 0.9276 Action: Privilege Escalation Attack \n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: 99.0\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: -1\n",
            "Episode 25 | Reward: 99.0\n",
            "Episode 25 completed. Total Reward = 129.0, Epsilon = 0.9249 Action: Privilege Escalation Attack \n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: 99.0\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: -1\n",
            "Episode 26 | Reward: 99.0\n",
            "Episode 26 completed. Total Reward = 155.0, Epsilon = 0.9221 Action: Privilege Escalation Attack \n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: 99.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1.0\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: -1\n",
            "Episode 27 | Reward: 99.0\n",
            "Episode 27 completed. Total Reward = 41.0, Epsilon = 0.9193 Action: Privilege Escalation Attack \n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: 99.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1.0\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: -1\n",
            "Episode 28 | Reward: 99.0\n",
            "Episode 28 completed. Total Reward = 51.0, Epsilon = 0.9166 Action: Privilege Escalation Attack \n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1.0\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: -1\n",
            "Episode 29 | Reward: 99.0\n",
            "Episode 29 | Reward: 99.0\n",
            "Episode 29 completed. Total Reward = 59.0, Epsilon = 0.9138 Action: Privilege Escalation Attack \n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: 99.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1.0\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: -1\n",
            "Episode 30 | Reward: 99.0\n",
            "Episode 30 completed. Total Reward = 105.0, Epsilon = 0.9111 Action: Privilege Escalation Attack \n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: 99.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: -1.0\n",
            "Episode 31 | Reward: -1\n",
            "Episode 31 | Reward: 99.0\n",
            "Episode 31 completed. Total Reward = 121.0, Epsilon = 0.9083 Action: Privilege Escalation Attack \n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: 99.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1.0\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: -1\n",
            "Episode 32 | Reward: 99.0\n",
            "Episode 32 completed. Total Reward = 102.0, Epsilon = 0.9056 Action: Privilege Escalation Attack \n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: 99.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1.0\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: -1\n",
            "Episode 33 | Reward: 99.0\n",
            "Episode 33 completed. Total Reward = 106.0, Epsilon = 0.9029 Action: Privilege Escalation Attack \n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: 99.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1\n",
            "Episode 34 | Reward: -1.0\n",
            "Episode 34 | Reward: 99.0\n",
            "Episode 34 completed. Total Reward = 106.0, Epsilon = 0.9002 Action: Privilege Escalation Attack \n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: 99.0\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: -1\n",
            "Episode 35 | Reward: 99.0\n",
            "Episode 35 completed. Total Reward = 151.0, Epsilon = 0.8975 Action: Privilege Escalation Attack \n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: 99.0\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: -1\n",
            "Episode 36 | Reward: 99.0\n",
            "Episode 36 completed. Total Reward = 103.0, Epsilon = 0.8948 Action: Privilege Escalation Attack \n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: 99.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1.0\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: -1\n",
            "Episode 37 | Reward: 99.0\n",
            "Episode 37 completed. Total Reward = 57.0, Epsilon = 0.8921 Action: Privilege Escalation Attack \n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: 99.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1.0\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: -1\n",
            "Episode 38 | Reward: 99.0\n",
            "Episode 38 completed. Total Reward = 91.0, Epsilon = 0.8894 Action: Privilege Escalation Attack \n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: 99.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: -1.0\n",
            "Episode 39 | Reward: -1\n",
            "Episode 39 | Reward: 99.0\n",
            "Episode 39 completed. Total Reward = 125.0, Epsilon = 0.8868 Action: Privilege Escalation Attack \n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: 99.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1.0\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: -1\n",
            "Episode 40 | Reward: 99.0\n",
            "Episode 40 completed. Total Reward = 131.0, Epsilon = 0.8841 Action: Privilege Escalation Attack \n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: 99.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1.0\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: -1\n",
            "Episode 41 | Reward: 99.0\n",
            "Episode 41 completed. Total Reward = 71.0, Epsilon = 0.8814 Action: Privilege Escalation Attack \n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: 99.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1.0\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: -1\n",
            "Episode 42 | Reward: 99.0\n",
            "Episode 42 completed. Total Reward = 77.0, Epsilon = 0.8788 Action: Privilege Escalation Attack \n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: 99.0\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: -1\n",
            "Episode 43 | Reward: 99.0\n",
            "Episode 43 completed. Total Reward = 69.0, Epsilon = 0.8762 Action: Privilege Escalation Attack \n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: 99.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1.0\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: -1\n",
            "Episode 44 | Reward: 99.0\n",
            "Episode 44 completed. Total Reward = 126.0, Epsilon = 0.8735 Action: Privilege Escalation Attack \n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: 99.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: -1.0\n",
            "Episode 45 | Reward: -1\n",
            "Episode 45 | Reward: 99.0\n",
            "Episode 45 completed. Total Reward = 91.0, Epsilon = 0.8709 Action: Privilege Escalation Attack \n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: 99.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1\n",
            "Episode 46 | Reward: -1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2fe27f60970c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Predict Threat Type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mstate_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Ensure detected threats match only the allowed threat IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2fe27f60970c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_value_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mthreat_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreat_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nasim\n",
        "!pip install neo4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9AuJLLFuKTc",
        "outputId": "00ee63b1-6bc1-44f2-c874-667c73045fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nasim\n",
            "  Downloading nasim-0.12.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.11/dist-packages (from nasim) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from nasim) (1.26.4)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from nasim) (6.0.2)\n",
            "Requirement already satisfied: prettytable>=0.7 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.14.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable>=0.7->nasim) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1->nasim) (1.17.0)\n",
            "Downloading nasim-0.12.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nasim\n",
            "Successfully installed nasim-0.12.0\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.1)\n",
            "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neo4j\n",
            "Successfully installed neo4j-5.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4:30pm\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j Configuration\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:11755\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "# Connect to Neo4j\n",
        "class Neo4jConnector:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self):\n",
        "        \"\"\"Fetch attack details dynamically from Neo4j\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC)\n",
        "        RETURN capec.ID AS CAPEC_ID, capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return {record[\"CAPEC_ID\"]: record.data() for record in result}  # Return a dictionary {ID: Details}\n",
        "\n",
        "    def get_threat_by_id(self, threat_id):\n",
        "        \"\"\"Fetch attack details for a given CAPEC_ID\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (capec:CAPEC {ID: $threat_id})\n",
        "        RETURN capec.Name AS CAPEC_Name, capec.Description AS CAPEC_Description\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, threat_id=threat_id)\n",
        "            return result.single()  # Return single record\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "\n",
        "# ✅ Provide a list of valid attack IDs from Neo4j (Example: Only allow certain threats)\n",
        "allowed_attack_ids = [\"CAPEC-1\", \"CAPEC-42\", \"CAPEC-99\"]\n",
        "filtered_attack_data = {key: attack_data[key] for key in allowed_attack_ids if key in attack_data}\n",
        "\n",
        "# Extract Known Threats\n",
        "valid_threats = list(filtered_attack_data.keys())  # Only keep valid threat IDs\n",
        "num_threats = max(1, len(valid_threats))\n",
        "\n",
        "print(f\"Valid Threat IDs: {valid_threats}\")\n",
        "print(f\"Number of Known Threat Categories: {num_threats}\")\n",
        "\n",
        "# Threat Mapping\n",
        "def map_threat_id(index):\n",
        "    \"\"\"Maps predicted index to allowed CAPEC_ID\"\"\"\n",
        "    if 0 <= index < len(valid_threats):\n",
        "        return valid_threats[index]\n",
        "    return None  # If invalid, return None\n",
        "\n",
        "# Define DQN Model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "        self.threat_layer = nn.Linear(128, num_threats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# Experience Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# Action Selection\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, env.action_space.n - 1)\n",
        "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        return policy_net(state_tensor)[0].argmax().item()\n",
        "\n",
        "# Train DQN Model\n",
        "def train_dqn():\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, threat_types = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor([float(d) for d in dones]).unsqueeze(1)\n",
        "\n",
        "    threat_types = torch.clamp(torch.LongTensor(threat_types), 0, num_threats - 1)\n",
        "\n",
        "    q_values, threat_preds = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions)\n",
        "    next_q_values, _ = target_net(next_states)\n",
        "    target_q_values = rewards + GAMMA * next_q_values.max(1, keepdim=True)[0] * (1 - dones)\n",
        "\n",
        "    q_loss = nn.MSELoss()(q_values, target_q_values.detach())\n",
        "    threat_loss = nn.CrossEntropyLoss()(threat_preds, threat_types)\n",
        "    loss = q_loss + threat_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    state = np.zeros(state_dim) if state is None or len(state) == 0 else state\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        next_state = np.zeros(state_dim) if next_state is None or len(next_state) == 0 else next_state\n",
        "\n",
        "        # Predict Threat Type\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "\n",
        "        # Ensure detected threats match only the allowed threat IDs\n",
        "        threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "        threat_id = map_threat_id(threat_type)\n",
        "\n",
        "        # Query Neo4j for threat details\n",
        "        if threat_id:\n",
        "            threat_details = neo4j_db.get_threat_by_id(threat_id)\n",
        "            threat_description = threat_details[\"CAPEC_Name\"] if threat_details else \"Unknown Threat\"\n",
        "        else:\n",
        "            threat_description = \"No Threat Detected\"\n",
        "\n",
        "        # Store experience\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    # Update Target Network\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "    print(f\"Episode {episode}: Total Reward = {total_reward}, Epsilon = {epsilon:.4f}, Threat Detected: {threat_description}\")\n",
        "\n",
        "# Save Model\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "JVh_hh-VBVW8",
        "outputId": "c3691243-f9ea-439c-faf3-6f814d71177c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Threat IDs: []\n",
            "Number of Known Threat Categories: 1\n",
            "Episode 0: Total Reward = 100.0, Epsilon = 0.9970, Threat Detected: No Threat Detected\n",
            "Episode 1: Total Reward = 99.0, Epsilon = 0.9940, Threat Detected: No Threat Detected\n",
            "Episode 2: Total Reward = 132.0, Epsilon = 0.9910, Threat Detected: No Threat Detected\n",
            "Episode 3: Total Reward = 137.0, Epsilon = 0.9881, Threat Detected: No Threat Detected\n",
            "Episode 4: Total Reward = 42.0, Epsilon = 0.9851, Threat Detected: No Threat Detected\n",
            "Episode 5: Total Reward = 96.0, Epsilon = 0.9821, Threat Detected: No Threat Detected\n",
            "Episode 6: Total Reward = 54.0, Epsilon = 0.9792, Threat Detected: No Threat Detected\n",
            "Episode 7: Total Reward = 118.0, Epsilon = 0.9763, Threat Detected: No Threat Detected\n",
            "Episode 8: Total Reward = 103.0, Epsilon = 0.9733, Threat Detected: No Threat Detected\n",
            "Episode 9: Total Reward = 97.0, Epsilon = 0.9704, Threat Detected: No Threat Detected\n",
            "Episode 10: Total Reward = 99.0, Epsilon = 0.9675, Threat Detected: No Threat Detected\n",
            "Episode 11: Total Reward = 52.0, Epsilon = 0.9646, Threat Detected: No Threat Detected\n",
            "Episode 12: Total Reward = 100.0, Epsilon = 0.9617, Threat Detected: No Threat Detected\n",
            "Episode 13: Total Reward = 50.0, Epsilon = 0.9588, Threat Detected: No Threat Detected\n",
            "Episode 14: Total Reward = 23.0, Epsilon = 0.9559, Threat Detected: No Threat Detected\n",
            "Episode 15: Total Reward = 90.0, Epsilon = 0.9531, Threat Detected: No Threat Detected\n",
            "Episode 16: Total Reward = 112.0, Epsilon = 0.9502, Threat Detected: No Threat Detected\n",
            "Episode 17: Total Reward = 149.0, Epsilon = 0.9474, Threat Detected: No Threat Detected\n",
            "Episode 18: Total Reward = 23.0, Epsilon = 0.9445, Threat Detected: No Threat Detected\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e306cfa90704>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e306cfa90704>\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j Configuration\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:11755\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "# Connect to Neo4j\n",
        "class Neo4jConnector:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self):\n",
        "        \"\"\"Fetch attack details dynamically from Neo4j\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (cve:CVE)-[:RelatedAttackPattern]->(capec:CAPEC)\n",
        "        OPTIONAL MATCH (cve)-[:hasConsequence]->(con:Consequence)\n",
        "        OPTIONAL MATCH (cve)-[:hasMitigation]->(mit:Mitigation)\n",
        "        RETURN\n",
        "            cve.Name AS CVE_ID,\n",
        "            cve.Description AS Description,\n",
        "            capec.Name AS CAPEC_ID,\n",
        "            capec.Description AS CAPEC_Description,\n",
        "            con.Description AS Consequence,\n",
        "            mit.Description AS Mitigation\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return [record.data() for record in result]\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "num_threats = max(1, len(attack_data))\n",
        "\n",
        "print(f\"Number of Threat Categories: {num_threats}\")\n",
        "\n",
        "# Threat Mapping\n",
        "def map_threat_type(index):\n",
        "    if index < len(attack_data):\n",
        "        return attack_data[index][\"CAPEC_Description\"]\n",
        "    return \"Unknown Threat\"\n",
        "\n",
        "# Define DQN Model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "        self.threat_layer = nn.Linear(128, num_threats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# Experience Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# Action Selection\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, env.action_space.n - 1)\n",
        "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        return policy_net(state_tensor)[0].argmax().item()\n",
        "\n",
        "# Train DQN Model\n",
        "def train_dqn():\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, threat_types = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor([float(d) for d in dones]).unsqueeze(1)\n",
        "\n",
        "    threat_types = torch.clamp(torch.LongTensor(threat_types), 0, num_threats - 1)\n",
        "\n",
        "    q_values, threat_preds = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions)\n",
        "    next_q_values, _ = target_net(next_states)\n",
        "    target_q_values = rewards + GAMMA * next_q_values.max(1, keepdim=True)[0] * (1 - dones)\n",
        "\n",
        "    q_loss = nn.MSELoss()(q_values, target_q_values.detach())\n",
        "    threat_loss = nn.CrossEntropyLoss()(threat_preds, threat_types)\n",
        "    loss = q_loss + threat_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    state = np.zeros(state_dim) if state is None or len(state) == 0 else state\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        next_state = np.zeros(state_dim) if next_state is None or len(next_state) == 0 else next_state\n",
        "\n",
        "        # Predict Threat Type\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "\n",
        "        if threat_prediction.numel() == 0 or threat_prediction.shape[1] != num_threats:\n",
        "            print(\"Invalid Threat Prediction! Defaulting to 0\")\n",
        "            threat_type = 0\n",
        "        else:\n",
        "            threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "\n",
        "        threat_type = max(0, min(threat_type, num_threats - 1))\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    # Update Target Network\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "    print(f\"Episode {episode}: Total Reward = {total_reward}, Epsilon = {epsilon:.4f}, Threat Detected: {map_threat_type(threat_type)}\")\n",
        "\n",
        "# Save Model\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPBkmpCi461b",
        "outputId": "d426faba-9d56-474c-ccd3-dda10c7de193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Threat Categories: 1\n",
            "Episode 0: Total Reward = 112.0, Epsilon = 0.9970, Threat Detected: Unknown Threat\n",
            "Episode 1: Total Reward = 147.0, Epsilon = 0.9940, Threat Detected: Unknown Threat\n",
            "Episode 2: Total Reward = 77.0, Epsilon = 0.9910, Threat Detected: Unknown Threat\n",
            "Episode 3: Total Reward = 86.0, Epsilon = 0.9881, Threat Detected: Unknown Threat\n",
            "Episode 4: Total Reward = 61.0, Epsilon = 0.9851, Threat Detected: Unknown Threat\n",
            "Episode 5: Total Reward = 47.0, Epsilon = 0.9821, Threat Detected: Unknown Threat\n",
            "Episode 6: Total Reward = 104.0, Epsilon = 0.9792, Threat Detected: Unknown Threat\n",
            "Episode 7: Total Reward = -18.0, Epsilon = 0.9763, Threat Detected: Unknown Threat\n",
            "Episode 8: Total Reward = 96.0, Epsilon = 0.9733, Threat Detected: Unknown Threat\n",
            "Episode 9: Total Reward = 97.0, Epsilon = 0.9704, Threat Detected: Unknown Threat\n",
            "Episode 10: Total Reward = 26.0, Epsilon = 0.9675, Threat Detected: Unknown Threat\n",
            "Episode 11: Total Reward = 113.0, Epsilon = 0.9646, Threat Detected: Unknown Threat\n",
            "Episode 12: Total Reward = 128.0, Epsilon = 0.9617, Threat Detected: Unknown Threat\n",
            "Episode 13: Total Reward = 75.0, Epsilon = 0.9588, Threat Detected: Unknown Threat\n",
            "Episode 14: Total Reward = 111.0, Epsilon = 0.9559, Threat Detected: Unknown Threat\n",
            "Episode 15: Total Reward = 96.0, Epsilon = 0.9531, Threat Detected: Unknown Threat\n",
            "Episode 16: Total Reward = 117.0, Epsilon = 0.9502, Threat Detected: Unknown Threat\n",
            "Episode 17: Total Reward = 121.0, Epsilon = 0.9474, Threat Detected: Unknown Threat\n",
            "Episode 18: Total Reward = 85.0, Epsilon = 0.9445, Threat Detected: Unknown Threat\n",
            "Episode 19: Total Reward = 84.0, Epsilon = 0.9417, Threat Detected: Unknown Threat\n",
            "Episode 20: Total Reward = 95.0, Epsilon = 0.9389, Threat Detected: Unknown Threat\n",
            "Episode 21: Total Reward = 12.0, Epsilon = 0.9360, Threat Detected: Unknown Threat\n",
            "Episode 22: Total Reward = 75.0, Epsilon = 0.9332, Threat Detected: Unknown Threat\n",
            "Episode 23: Total Reward = 150.0, Epsilon = 0.9304, Threat Detected: Unknown Threat\n",
            "Episode 24: Total Reward = 117.0, Epsilon = 0.9276, Threat Detected: Unknown Threat\n",
            "Episode 25: Total Reward = 71.0, Epsilon = 0.9249, Threat Detected: Unknown Threat\n",
            "Episode 26: Total Reward = 133.0, Epsilon = 0.9221, Threat Detected: Unknown Threat\n",
            "Episode 27: Total Reward = 26.0, Epsilon = 0.9193, Threat Detected: Unknown Threat\n",
            "Episode 28: Total Reward = 143.0, Epsilon = 0.9166, Threat Detected: Unknown Threat\n",
            "Episode 29: Total Reward = 97.0, Epsilon = 0.9138, Threat Detected: Unknown Threat\n",
            "Episode 30: Total Reward = 20.0, Epsilon = 0.9111, Threat Detected: Unknown Threat\n",
            "Episode 31: Total Reward = 148.0, Epsilon = 0.9083, Threat Detected: Unknown Threat\n",
            "Episode 32: Total Reward = 77.0, Epsilon = 0.9056, Threat Detected: Unknown Threat\n",
            "Episode 33: Total Reward = 26.0, Epsilon = 0.9029, Threat Detected: Unknown Threat\n",
            "Episode 34: Total Reward = -25.0, Epsilon = 0.9002, Threat Detected: Unknown Threat\n",
            "Episode 35: Total Reward = 168.0, Epsilon = 0.8975, Threat Detected: Unknown Threat\n",
            "Episode 36: Total Reward = 81.0, Epsilon = 0.8948, Threat Detected: Unknown Threat\n",
            "Episode 37: Total Reward = 38.0, Epsilon = 0.8921, Threat Detected: Unknown Threat\n",
            "Episode 38: Total Reward = 140.0, Epsilon = 0.8894, Threat Detected: Unknown Threat\n",
            "Episode 39: Total Reward = 91.0, Epsilon = 0.8868, Threat Detected: Unknown Threat\n",
            "Episode 40: Total Reward = 100.0, Epsilon = 0.8841, Threat Detected: Unknown Threat\n",
            "Episode 41: Total Reward = 34.0, Epsilon = 0.8814, Threat Detected: Unknown Threat\n",
            "Episode 42: Total Reward = 61.0, Epsilon = 0.8788, Threat Detected: Unknown Threat\n",
            "Episode 43: Total Reward = 132.0, Epsilon = 0.8762, Threat Detected: Unknown Threat\n",
            "Episode 44: Total Reward = 57.0, Epsilon = 0.8735, Threat Detected: Unknown Threat\n",
            "Episode 45: Total Reward = 103.0, Epsilon = 0.8709, Threat Detected: Unknown Threat\n",
            "Episode 46: Total Reward = 156.0, Epsilon = 0.8683, Threat Detected: Unknown Threat\n",
            "Episode 47: Total Reward = 136.0, Epsilon = 0.8657, Threat Detected: Unknown Threat\n",
            "Episode 48: Total Reward = 109.0, Epsilon = 0.8631, Threat Detected: Unknown Threat\n",
            "Episode 49: Total Reward = 126.0, Epsilon = 0.8605, Threat Detected: Unknown Threat\n",
            "Episode 50: Total Reward = -2.0, Epsilon = 0.8579, Threat Detected: Unknown Threat\n",
            "Episode 51: Total Reward = 112.0, Epsilon = 0.8554, Threat Detected: Unknown Threat\n",
            "Episode 52: Total Reward = 39.0, Epsilon = 0.8528, Threat Detected: Unknown Threat\n",
            "Episode 53: Total Reward = 128.0, Epsilon = 0.8502, Threat Detected: Unknown Threat\n",
            "Episode 54: Total Reward = 117.0, Epsilon = 0.8477, Threat Detected: Unknown Threat\n",
            "Episode 55: Total Reward = 25.0, Epsilon = 0.8451, Threat Detected: Unknown Threat\n",
            "Episode 56: Total Reward = 150.0, Epsilon = 0.8426, Threat Detected: Unknown Threat\n",
            "Episode 57: Total Reward = 124.0, Epsilon = 0.8401, Threat Detected: Unknown Threat\n",
            "Episode 58: Total Reward = 112.0, Epsilon = 0.8376, Threat Detected: Unknown Threat\n",
            "Episode 59: Total Reward = 114.0, Epsilon = 0.8350, Threat Detected: Unknown Threat\n",
            "Episode 60: Total Reward = 165.0, Epsilon = 0.8325, Threat Detected: Unknown Threat\n",
            "Episode 61: Total Reward = 100.0, Epsilon = 0.8300, Threat Detected: Unknown Threat\n",
            "Episode 62: Total Reward = 104.0, Epsilon = 0.8276, Threat Detected: Unknown Threat\n",
            "Episode 63: Total Reward = 89.0, Epsilon = 0.8251, Threat Detected: Unknown Threat\n",
            "Episode 64: Total Reward = 54.0, Epsilon = 0.8226, Threat Detected: Unknown Threat\n",
            "Episode 65: Total Reward = 171.0, Epsilon = 0.8201, Threat Detected: Unknown Threat\n",
            "Episode 66: Total Reward = 76.0, Epsilon = 0.8177, Threat Detected: Unknown Threat\n",
            "Episode 67: Total Reward = 104.0, Epsilon = 0.8152, Threat Detected: Unknown Threat\n",
            "Episode 68: Total Reward = 104.0, Epsilon = 0.8128, Threat Detected: Unknown Threat\n",
            "Episode 69: Total Reward = 21.0, Epsilon = 0.8103, Threat Detected: Unknown Threat\n",
            "Episode 70: Total Reward = 126.0, Epsilon = 0.8079, Threat Detected: Unknown Threat\n",
            "Episode 71: Total Reward = 81.0, Epsilon = 0.8055, Threat Detected: Unknown Threat\n",
            "Episode 72: Total Reward = 91.0, Epsilon = 0.8031, Threat Detected: Unknown Threat\n",
            "Episode 73: Total Reward = 126.0, Epsilon = 0.8006, Threat Detected: Unknown Threat\n",
            "Episode 74: Total Reward = 164.0, Epsilon = 0.7982, Threat Detected: Unknown Threat\n",
            "Episode 75: Total Reward = 112.0, Epsilon = 0.7959, Threat Detected: Unknown Threat\n",
            "Episode 76: Total Reward = 78.0, Epsilon = 0.7935, Threat Detected: Unknown Threat\n",
            "Episode 77: Total Reward = 131.0, Epsilon = 0.7911, Threat Detected: Unknown Threat\n",
            "Episode 78: Total Reward = 104.0, Epsilon = 0.7887, Threat Detected: Unknown Threat\n",
            "Episode 79: Total Reward = 69.0, Epsilon = 0.7863, Threat Detected: Unknown Threat\n",
            "Episode 80: Total Reward = 87.0, Epsilon = 0.7840, Threat Detected: Unknown Threat\n",
            "Episode 81: Total Reward = 144.0, Epsilon = 0.7816, Threat Detected: Unknown Threat\n",
            "Episode 82: Total Reward = 64.0, Epsilon = 0.7793, Threat Detected: Unknown Threat\n",
            "Episode 83: Total Reward = 75.0, Epsilon = 0.7770, Threat Detected: Unknown Threat\n",
            "Episode 84: Total Reward = 140.0, Epsilon = 0.7746, Threat Detected: Unknown Threat\n",
            "Episode 85: Total Reward = 180.0, Epsilon = 0.7723, Threat Detected: Unknown Threat\n",
            "Episode 86: Total Reward = 136.0, Epsilon = 0.7700, Threat Detected: Unknown Threat\n",
            "Episode 87: Total Reward = 112.0, Epsilon = 0.7677, Threat Detected: Unknown Threat\n",
            "Episode 88: Total Reward = 152.0, Epsilon = 0.7654, Threat Detected: Unknown Threat\n",
            "Episode 89: Total Reward = 172.0, Epsilon = 0.7631, Threat Detected: Unknown Threat\n",
            "Episode 90: Total Reward = 127.0, Epsilon = 0.7608, Threat Detected: Unknown Threat\n",
            "Episode 91: Total Reward = 134.0, Epsilon = 0.7585, Threat Detected: Unknown Threat\n",
            "Episode 92: Total Reward = 24.0, Epsilon = 0.7562, Threat Detected: Unknown Threat\n",
            "Episode 93: Total Reward = 142.0, Epsilon = 0.7540, Threat Detected: Unknown Threat\n",
            "Episode 94: Total Reward = 106.0, Epsilon = 0.7517, Threat Detected: Unknown Threat\n",
            "Episode 95: Total Reward = 141.0, Epsilon = 0.7494, Threat Detected: Unknown Threat\n",
            "Episode 96: Total Reward = 114.0, Epsilon = 0.7472, Threat Detected: Unknown Threat\n",
            "Episode 97: Total Reward = 101.0, Epsilon = 0.7449, Threat Detected: Unknown Threat\n",
            "Episode 98: Total Reward = 91.0, Epsilon = 0.7427, Threat Detected: Unknown Threat\n",
            "Episode 99: Total Reward = 159.0, Epsilon = 0.7405, Threat Detected: Unknown Threat\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzJABYB_7Z9l",
        "outputId": "432b77e2-b057-474d-e498-0589ccb3af58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS THE FIXED DQN + NEO4J + NASIM MODEL\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "import json\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j Configuration\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:11755\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "# Connect to Neo4j\n",
        "class Neo4jConnector:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self):\n",
        "        \"\"\"Fetch attack details dynamically from Neo4j\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (cve:CVE)-[:RelatedAttackPattern]->(capec:CAPEC)\n",
        "        OPTIONAL MATCH (cve)-[:hasConsequence]->(con:Consequence)\n",
        "        OPTIONAL MATCH (cve)-[:hasMitigation]->(mit:Mitigation)\n",
        "        RETURN cve.Name AS CVE_ID, cve.Description AS Description, capec.Name AS CAPEC_ID, capec.Description AS CAPEC_Description,\n",
        "               con.Description AS Consequence, mit.Description AS Mitigation\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return [record.data() for record in result]\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "\n",
        "# Fetch attack data\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "num_threats = max(1, len(attack_data))  # Ensure at least 1 threat class\n",
        "\n",
        "print(f\"Number of Threat Categories: {num_threats}\")\n",
        "\n",
        "# Define DQN Model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)\n",
        "        self.threat_layer = nn.Linear(128, num_threats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# Experience Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# Action Selection\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, env.action_space.n - 1)\n",
        "    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        return policy_net(state_tensor)[0].argmax().item()\n",
        "\n",
        "# Train DQN Model\n",
        "def train_dqn():\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, threat_types = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor([float(d) for d in dones]).unsqueeze(1)\n",
        "\n",
        "    # Fix: Ensure threat_types are within range\n",
        "    threat_types = torch.clamp(torch.LongTensor(threat_types), 0, num_threats - 1)\n",
        "\n",
        "    q_values, threat_preds = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions)\n",
        "    next_q_values, _ = target_net(next_states)\n",
        "    target_q_values = rewards + GAMMA * next_q_values.max(1, keepdim=True)[0] * (1 - dones)\n",
        "\n",
        "    q_loss = nn.MSELoss()(q_values, target_q_values.detach())\n",
        "    threat_loss = nn.CrossEntropyLoss()(threat_preds, threat_types)\n",
        "    loss = q_loss + threat_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Training Loop\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    state = np.zeros(state_dim) if state is None or len(state) == 0 else state\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        next_state = np.zeros(state_dim) if next_state is None or len(next_state) == 0 else next_state\n",
        "\n",
        "        # Predict Threat Type\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "\n",
        "        if threat_prediction.numel() == 0 or threat_prediction.shape[1] != num_threats:\n",
        "            print(\"Invalid Threat Prediction! Defaulting to 0\")\n",
        "            threat_type = 0\n",
        "        else:\n",
        "            threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "\n",
        "        # Ensure threat_type is within valid range\n",
        "        threat_type = max(0, min(threat_type, num_threats - 1))\n",
        "\n",
        "        # Store experience\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    # Update Target Network\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "    print(f\"Episode {episode}: Total Reward = {total_reward}, Epsilon = {epsilon:.4f}\")\n",
        "\n",
        "# Save Model\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2aVMTAWcbNl",
        "outputId": "f92d7ff7-b94a-4f67-9edb-5e68781928e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nasim/envs/render.py:17: UserWarning: Unable to import Matplotlib with TkAgg backend due to following exception: \"<class 'ImportError'> Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running\". NASIM can still run but GUI functionallity may not work as expected.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Threat Categories: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f6fe2a3f40ee>:120: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  states = torch.FloatTensor(states)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Total Reward = 30.0, Epsilon = 0.9970\n",
            "Episode 1: Total Reward = 96.0, Epsilon = 0.9940\n",
            "Episode 2: Total Reward = 2.0, Epsilon = 0.9910\n",
            "Episode 3: Total Reward = 61.0, Epsilon = 0.9881\n",
            "Episode 4: Total Reward = 121.0, Epsilon = 0.9851\n",
            "Episode 5: Total Reward = 131.0, Epsilon = 0.9821\n",
            "Episode 6: Total Reward = 122.0, Epsilon = 0.9792\n",
            "Episode 7: Total Reward = 101.0, Epsilon = 0.9763\n",
            "Episode 8: Total Reward = 64.0, Epsilon = 0.9733\n",
            "Episode 9: Total Reward = 35.0, Epsilon = 0.9704\n",
            "Episode 10: Total Reward = 141.0, Epsilon = 0.9675\n",
            "Episode 11: Total Reward = 138.0, Epsilon = 0.9646\n",
            "Episode 12: Total Reward = 65.0, Epsilon = 0.9617\n",
            "Episode 13: Total Reward = 79.0, Epsilon = 0.9588\n",
            "Episode 14: Total Reward = 155.0, Epsilon = 0.9559\n",
            "Episode 15: Total Reward = 137.0, Epsilon = 0.9531\n",
            "Episode 16: Total Reward = 126.0, Epsilon = 0.9502\n",
            "Episode 17: Total Reward = 101.0, Epsilon = 0.9474\n",
            "Episode 18: Total Reward = 154.0, Epsilon = 0.9445\n",
            "Episode 19: Total Reward = 122.0, Epsilon = 0.9417\n",
            "Episode 20: Total Reward = 149.0, Epsilon = 0.9389\n",
            "Episode 21: Total Reward = 85.0, Epsilon = 0.9360\n",
            "Episode 22: Total Reward = 156.0, Epsilon = 0.9332\n",
            "Episode 23: Total Reward = 106.0, Epsilon = 0.9304\n",
            "Episode 24: Total Reward = 21.0, Epsilon = 0.9276\n",
            "Episode 25: Total Reward = 108.0, Epsilon = 0.9249\n",
            "Episode 26: Total Reward = 46.0, Epsilon = 0.9221\n",
            "Episode 27: Total Reward = 98.0, Epsilon = 0.9193\n",
            "Episode 28: Total Reward = 92.0, Epsilon = 0.9166\n",
            "Episode 29: Total Reward = 20.0, Epsilon = 0.9138\n",
            "Episode 30: Total Reward = 111.0, Epsilon = 0.9111\n",
            "Episode 31: Total Reward = 117.0, Epsilon = 0.9083\n",
            "Episode 32: Total Reward = 69.0, Epsilon = 0.9056\n",
            "Episode 33: Total Reward = 134.0, Epsilon = 0.9029\n",
            "Episode 34: Total Reward = 35.0, Epsilon = 0.9002\n",
            "Episode 35: Total Reward = 5.0, Epsilon = 0.8975\n",
            "Episode 36: Total Reward = 70.0, Epsilon = 0.8948\n",
            "Episode 37: Total Reward = 102.0, Epsilon = 0.8921\n",
            "Episode 38: Total Reward = 69.0, Epsilon = 0.8894\n",
            "Episode 39: Total Reward = 155.0, Epsilon = 0.8868\n",
            "Episode 40: Total Reward = 106.0, Epsilon = 0.8841\n",
            "Episode 41: Total Reward = 104.0, Epsilon = 0.8814\n",
            "Episode 42: Total Reward = 70.0, Epsilon = 0.8788\n",
            "Episode 43: Total Reward = 109.0, Epsilon = 0.8762\n",
            "Episode 44: Total Reward = 159.0, Epsilon = 0.8735\n",
            "Episode 45: Total Reward = 166.0, Epsilon = 0.8709\n",
            "Episode 46: Total Reward = 51.0, Epsilon = 0.8683\n",
            "Episode 47: Total Reward = 152.0, Epsilon = 0.8657\n",
            "Episode 48: Total Reward = 93.0, Epsilon = 0.8631\n",
            "Episode 49: Total Reward = 90.0, Epsilon = 0.8605\n",
            "Episode 50: Total Reward = 36.0, Epsilon = 0.8579\n",
            "Episode 51: Total Reward = 106.0, Epsilon = 0.8554\n",
            "Episode 52: Total Reward = 88.0, Epsilon = 0.8528\n",
            "Episode 53: Total Reward = 17.0, Epsilon = 0.8502\n",
            "Episode 54: Total Reward = 105.0, Epsilon = 0.8477\n",
            "Episode 55: Total Reward = 42.0, Epsilon = 0.8451\n",
            "Episode 56: Total Reward = 130.0, Epsilon = 0.8426\n",
            "Episode 57: Total Reward = 102.0, Epsilon = 0.8401\n",
            "Episode 58: Total Reward = 157.0, Epsilon = 0.8376\n",
            "Episode 59: Total Reward = 83.0, Epsilon = 0.8350\n",
            "Episode 60: Total Reward = 83.0, Epsilon = 0.8325\n",
            "Episode 61: Total Reward = 46.0, Epsilon = 0.8300\n",
            "Episode 62: Total Reward = 137.0, Epsilon = 0.8276\n",
            "Episode 63: Total Reward = 155.0, Epsilon = 0.8251\n",
            "Episode 64: Total Reward = 66.0, Epsilon = 0.8226\n",
            "Episode 65: Total Reward = 108.0, Epsilon = 0.8201\n",
            "Episode 66: Total Reward = 113.0, Epsilon = 0.8177\n",
            "Episode 67: Total Reward = 66.0, Epsilon = 0.8152\n",
            "Episode 68: Total Reward = 130.0, Epsilon = 0.8128\n",
            "Episode 69: Total Reward = 96.0, Epsilon = 0.8103\n",
            "Episode 70: Total Reward = 4.0, Epsilon = 0.8079\n",
            "Episode 71: Total Reward = 15.0, Epsilon = 0.8055\n",
            "Episode 72: Total Reward = -46.0, Epsilon = 0.8031\n",
            "Episode 73: Total Reward = 133.0, Epsilon = 0.8006\n",
            "Episode 74: Total Reward = 56.0, Epsilon = 0.7982\n",
            "Episode 75: Total Reward = 87.0, Epsilon = 0.7959\n",
            "Episode 76: Total Reward = 98.0, Epsilon = 0.7935\n",
            "Episode 77: Total Reward = -19.0, Epsilon = 0.7911\n",
            "Episode 78: Total Reward = -52.0, Epsilon = 0.7887\n",
            "Episode 79: Total Reward = -4.0, Epsilon = 0.7863\n",
            "Episode 80: Total Reward = 12.0, Epsilon = 0.7840\n",
            "Episode 81: Total Reward = 153.0, Epsilon = 0.7816\n",
            "Episode 82: Total Reward = 107.0, Epsilon = 0.7793\n",
            "Episode 83: Total Reward = 150.0, Epsilon = 0.7770\n",
            "Episode 84: Total Reward = 114.0, Epsilon = 0.7746\n",
            "Episode 85: Total Reward = 127.0, Epsilon = 0.7723\n",
            "Episode 86: Total Reward = 53.0, Epsilon = 0.7700\n",
            "Episode 87: Total Reward = -6.0, Epsilon = 0.7677\n",
            "Episode 88: Total Reward = -38.0, Epsilon = 0.7654\n",
            "Episode 89: Total Reward = 159.0, Epsilon = 0.7631\n",
            "Episode 90: Total Reward = 90.0, Epsilon = 0.7608\n",
            "Episode 91: Total Reward = 55.0, Epsilon = 0.7585\n",
            "Episode 92: Total Reward = 105.0, Epsilon = 0.7562\n",
            "Episode 93: Total Reward = 69.0, Epsilon = 0.7540\n",
            "Episode 94: Total Reward = 119.0, Epsilon = 0.7517\n",
            "Episode 95: Total Reward = 65.0, Epsilon = 0.7494\n",
            "Episode 96: Total Reward = 151.0, Epsilon = 0.7472\n",
            "Episode 97: Total Reward = 142.0, Epsilon = 0.7449\n",
            "Episode 98: Total Reward = 90.0, Epsilon = 0.7427\n",
            "Episode 99: Total Reward = 45.0, Epsilon = 0.7405\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "uri = \"bolt://0.tcp.in.ngrok.io:11755\"  # Change to your Neo4j instance\n",
        "user = \"neo4j\"\n",
        "password = \"12345678\"\n",
        "\n",
        "try:\n",
        "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "    with driver.session() as session:\n",
        "        result = session.run(\"MATCH (n) RETURN n LIMIT 5\")  # Fetch some data\n",
        "        for record in result:\n",
        "            print(record)\n",
        "    print(\"Neo4j connection successful!\")\n",
        "except Exception as e:\n",
        "    print(\"Neo4j connection failed:\", e)\n",
        "\n",
        "\n",
        "\n",
        "attack_type = \"SQL Injection\"  # Replace with detected attack type from RL model\n",
        "query = f\"MATCH (a:Attack {{type: '{attack_type}'}}) RETURN a.description\"\n",
        "with driver.session() as session:\n",
        "    result = session.run(query)\n",
        "    for record in result:\n",
        "        print(\"Attack Description:\", record[\"a.description\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOuBfm0po37k",
        "outputId": "7c7dafe3-546c-4735-9fd9-9bfbe204d636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Record n=<Node element_id='0' labels=frozenset({'GeneralInfo_CVE'}) properties={'Data_Format': 'MITRE', 'Data_Type': 'CVE', 'No_CVEs': '10861', 'Data_Version': '4.0', 'Timestamp': '2021-09-15T07:00Z'}>>\n",
            "<Record n=<Node element_id='1' labels=frozenset({'CVE'}) properties={'Assigner': 'secure@intel.com', 'Description': ['Observable timing discrepancy in Intel(R) IPP before version 2020 update 1 may allow authorized user to potentially enable information disclosure via local access.'], 'Published_Date': '2021-06-09T20:15Z', 'Last_Modified_Date': '2021-06-28T18:03Z', 'Name': 'CVE-2021-0001'}>>\n",
            "<Record n=<Node element_id='2' labels=frozenset({'CVE'}) properties={'Assigner': 'secure@intel.com', 'Description': ['Improper conditions check in some Intel(R) Ethernet Controllers 800 series Linux drivers before version 1.4.11 may allow an authenticated user to potentially enable information disclosure or denial of service via local access.'], 'Published_Date': '2021-08-11T13:15Z', 'Last_Modified_Date': '2021-08-27T07:15Z', 'Name': 'CVE-2021-0002'}>>\n",
            "<Record n=<Node element_id='3' labels=frozenset({'CVE'}) properties={'Assigner': 'secure@intel.com', 'Description': ['Improper conditions check in some Intel(R) Ethernet Controllers 800 series Linux drivers before version 1.4.11 may allow an authenticated user to potentially enable information disclosure via local access.'], 'Published_Date': '2021-08-11T13:15Z', 'Last_Modified_Date': '2021-09-14T18:36Z', 'Name': 'CVE-2021-0003'}>>\n",
            "<Record n=<Node element_id='4' labels=frozenset({'CVE'}) properties={'Assigner': 'secure@intel.com', 'Description': ['Improper buffer restrictions in the firmware of Intel(R) Ethernet Adapters 800 Series Controllers and associated adapters before version 1.5.3.0 may allow a privileged user to potentially enable denial of service via local access.'], 'Published_Date': '2021-08-11T13:15Z', 'Last_Modified_Date': '2021-09-14T18:36Z', 'Name': 'CVE-2021-0004'}>>\n",
            "Neo4j connection successful!\n",
            "This type of attack does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS THE REFINED DQN MODEL CONNECTING NEO4J + NASIM\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "import json\n",
        "from collections import deque\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j Configuration (Modify with actual credentials)\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:11755\"  # Replace with your ngrok forwarding address\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "# Connect to Neo4j\n",
        "class Neo4jConnector:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_attack_data(self, attack_name=None):\n",
        "        \"\"\"Fetch attack details dynamically from Neo4j\"\"\"\n",
        "        query = \"\"\"\n",
        "        MATCH (cve:CVE)-[:RelatedAttackPattern]->(capec:CAPEC)\n",
        "        OPTIONAL MATCH (cve)-[:hasConsequence]->(con:Consequence)\n",
        "        OPTIONAL MATCH (cve)-[:hasMitigation]->(mit:Mitigation)\n",
        "        RETURN cve.Name AS CVE_ID, cve.Description AS Description,\n",
        "               capec.Name AS CAPEC_ID, capec.Description AS CAPEC_Description,\n",
        "               con.Description AS Consequence, mit.Description AS Mitigation\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query)\n",
        "            return [record.data() for record in result]\n",
        "\n",
        "# Initialize Neo4j Connection\n",
        "neo4j_db = Neo4jConnector(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
        "\n",
        "# Fetch attack data dynamically\n",
        "attack_data = neo4j_db.fetch_attack_data()\n",
        "\n",
        "# Define DQN Model with Threat Classification\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)  # Q-values for actions\n",
        "        self.threat_layer = nn.Linear(128, num_threats)  # Threat classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# Experience Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 100\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "num_threats = len(attack_data)  # Dynamically set based on attack data\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# Action Selection with Epsilon-Greedy Strategy\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, env.action_space.n - 1)\n",
        "    else:\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state_tensor)[0].argmax().item()\n",
        "\n",
        "# Train DQN Model\n",
        "def train_dqn():\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, threat_types = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor(dones).unsqueeze(1)\n",
        "    threat_types = torch.LongTensor(threat_types)\n",
        "\n",
        "    q_values, threat_preds = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions)\n",
        "    next_q_values, _ = target_net(next_states)\n",
        "    target_q_values = rewards + GAMMA * next_q_values.max(1, keepdim=True)[0] * (1 - dones)\n",
        "\n",
        "    q_loss = nn.MSELoss()(q_values, target_q_values.detach())\n",
        "    threat_loss = nn.CrossEntropyLoss()(threat_preds, threat_types)\n",
        "    loss = q_loss + threat_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Training Loop with Neo4j Integration\n",
        "epsilon = EPSILON\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    state = np.zeros(state_dim) if state is None or len(state) == 0 else state\n",
        "\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        next_state = np.zeros(state_dim) if next_state is None or len(next_state) == 0 else next_state\n",
        "\n",
        "        # Predict Threat Type\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "        threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "\n",
        "        # Fetch CVE Details from Neo4j\n",
        "        if 0 <= threat_type < len(attack_data):\n",
        "            detected_threat = attack_data[threat_type]\n",
        "            print(f\"Detected Threat: {detected_threat}\")\n",
        "        else:\n",
        "            print(f\"Warning: Threat type {threat_type} out of range.\")\n",
        "\n",
        "        # Adjust Reward Based on CVSS\n",
        "        reward += 10 if \"successful_attack\" in info else 0\n",
        "        reward -= 5 if \"false_positive\" in info else 0\n",
        "        reward -= 15 if \"missed_attack\" in info else 0\n",
        "\n",
        "        # Store experience\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    # Update Target Network\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "\n",
        "    print(f\"Episode {episode}: Total Reward = {total_reward}, Epsilon = {epsilon:.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if episode > 50 and np.std(reward_history[-50:]) < 1.0:\n",
        "        print(f\"Stopping early at Episode {episode} as rewards have stabilized.\")\n",
        "        break\n",
        "\n",
        "# Save Model\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "neo4j_db.close()\n",
        "print(\"Training complete. Model and logs saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8ElyfRPOgelF",
        "outputId": "37656b42-6899-4619-def8-b7578df8ceeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "argmax(): Expected reduction dim 1 to have non-zero size.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1659b9ed3575>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mstate_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mthreat_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreat_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Fetch CVE Details from Neo4j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: argmax(): Expected reduction dim 1 to have non-zero size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j Connection Details\n",
        "NEO4J_URI = \"bolt://0.tcp.in.ngrok.io:11755\"  # Update this if ngrok changes the port\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"12345678\"\n",
        "\n",
        "# Connect to Neo4j\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "\n",
        "# Function to Get CVE Details and Format Output\n",
        "def get_cve_details(cve_id):\n",
        "    query = f\"MATCH (c:CVE {{Name: '{cve_id}'}}) RETURN c\"\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query)\n",
        "        cve_list = []\n",
        "        for record in result:\n",
        "            node = record[\"c\"]\n",
        "            cve_info = {\n",
        "                \"CVE_ID\": node[\"Name\"],\n",
        "                \"Assigner\": node[\"Assigner\"],\n",
        "                \"Description\": node[\"Description\"][0],  # Extracting first description\n",
        "                \"Published Date\": node[\"Published_Date\"],\n",
        "                \"Last Modified Date\": node[\"Last_Modified_Date\"]\n",
        "            }\n",
        "            cve_list.append(cve_info)\n",
        "        return cve_list if cve_list else \"No CVE found.\"\n",
        "\n",
        "# Example Usage:\n",
        "cve_data = get_cve_details(\"CVE-2021-0009\")\n",
        "print(cve_data)  # Now returns formatted JSON\n",
        "\n",
        "# Close the driver when done\n",
        "driver.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voul99S2ZJxv",
        "outputId": "815c1c9e-8419-4ee7-cf2b-1001a00f79f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'CVE_ID': 'CVE-2021-0009', 'Assigner': 'secure@intel.com', 'Description': 'Out-of-bounds read in the firmware for Intel(R) Ethernet Adapters 800 Series Controllers and associated adapters before version 1.5.3.0 may allow an unauthenticated user to potentially enable denial of service via adjacent access.', 'Published Date': '2021-08-11T13:15Z', 'Last Modified Date': '2021-09-14T18:34Z'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJeFLM3qT6Pt",
        "outputId": "999200ea-b1e2-4fb6-a3bc-c7607211de40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nasim\n",
            "  Downloading nasim-0.12.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting gymnasium>=0.26 (from nasim)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from nasim) (1.26.4)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from nasim) (6.0.2)\n",
            "Requirement already satisfied: prettytable>=0.7 in /usr/local/lib/python3.11/dist-packages (from nasim) (3.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->nasim) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.26->nasim)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (4.55.6)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1->nasim) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable>=0.7->nasim) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1->nasim) (1.17.0)\n",
            "Downloading nasim-0.12.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, nasim\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 nasim-0.12.0\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import nasim\n",
        "from collections import deque\n",
        "import json\n",
        "\n",
        "# Define DQN Model with Threat Classification\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, num_threats):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.q_value_layer = nn.Linear(128, action_dim)  # Q-values for actions\n",
        "        self.threat_layer = nn.Linear(128, num_threats)  # Threat classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        q_values = self.q_value_layer(x)\n",
        "        threat_classification = torch.softmax(self.threat_layer(x), dim=1)\n",
        "        return q_values, threat_classification\n",
        "\n",
        "# Experience Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done, threat_type):\n",
        "        self.buffer.append((state, action, reward, next_state, done, threat_type))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.001\n",
        "EPSILON = 1.0\n",
        "EPSILON_DECAY = 0.997  # Faster decay\n",
        "MIN_EPSILON = 0.01\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10\n",
        "MAX_EPISODES = 1000  # Increased episodes\n",
        "\n",
        "# Initialize NASim Environment\n",
        "env = nasim.make_benchmark('tiny', flat_actions=True, flat_obs=True)\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "num_threats = 5  # Number of attack types to classify\n",
        "\n",
        "# Initialize Networks\n",
        "policy_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net = DQN(state_dim, action_dim, num_threats)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=ALPHA)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)  # Reduce LR every 50 episodes\n",
        "memory = ReplayBuffer(MEMORY_SIZE)\n",
        "\n",
        "# Action Selection with Epsilon-Greedy Strategy\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        action = random.randint(0, env.action_space.n - 1)  # Ensure valid integer action\n",
        "    else:\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            action = policy_net(state_tensor)[0].argmax().item()  # Get Q-values and select best action\n",
        "    return int(action)  # Ensure integer action for NASim\n",
        "\n",
        "# Train DQN Model\n",
        "def train_dqn():\n",
        "    if memory.size() < BATCH_SIZE:\n",
        "        return\n",
        "    batch = memory.sample(BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones, threat_types = zip(*batch)\n",
        "\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions).unsqueeze(1)\n",
        "    rewards = torch.FloatTensor(rewards).unsqueeze(1)\n",
        "    next_states = torch.FloatTensor(next_states)\n",
        "    dones = torch.FloatTensor([float(d) for d in dones]).unsqueeze(1)  # Convert to float\n",
        "    threat_types = torch.LongTensor(threat_types)\n",
        "\n",
        "    q_values, threat_preds = policy_net(states)\n",
        "    q_values = q_values.gather(1, actions)\n",
        "    next_q_values, _ = target_net(next_states)\n",
        "    target_q_values = rewards + GAMMA * next_q_values.max(1, keepdim=True)[0] * (1 - dones)\n",
        "\n",
        "    # Compute loss\n",
        "    q_loss = nn.MSELoss()(q_values, target_q_values.detach())\n",
        "    threat_loss = nn.CrossEntropyLoss()(threat_preds, threat_types)\n",
        "    loss = q_loss + threat_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Training Loop with Reward Shaping\n",
        "epsilon = EPSILON\n",
        "log_data = []\n",
        "reward_history = []\n",
        "\n",
        "for episode in range(MAX_EPISODES):\n",
        "    state, _ = env.reset()\n",
        "    if state is None or len(state) == 0:\n",
        "        state = np.zeros(state_dim)  # Ensure valid state\n",
        "\n",
        "    done = False\n",
        "    previous_action = None  # Track previous action for repeated action penalty\n",
        "    episode_log = []\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "        if next_state is None or len(next_state) == 0:\n",
        "            next_state = np.zeros(state_dim)  # Ensure valid next state\n",
        "\n",
        "        # Predict the threat type correctly\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "        _, threat_prediction = policy_net(state_tensor)\n",
        "        threat_type = torch.argmax(threat_prediction, dim=1).item()\n",
        "\n",
        "        # Reward Shaping Implementation\n",
        "        if \"successful_attack\" in info:\n",
        "            reward += 10  # Reward for detecting threats correctly\n",
        "        if \"false_positive\" in info:\n",
        "            reward -= 5  # Penalize false positives\n",
        "        if \"missed_attack\" in info:\n",
        "            reward -= 15  # Penalize missing an actual attack\n",
        "        if action == previous_action:\n",
        "            reward -= 2  # Penalize repeated actions\n",
        "\n",
        "        previous_action = action  # Update previous action\n",
        "\n",
        "        # Store experience\n",
        "        memory.push(state, action, reward, next_state, done, threat_type)\n",
        "        state = next_state\n",
        "        train_dqn()\n",
        "        total_reward += reward\n",
        "\n",
        "        # Log details\n",
        "        episode_log.append({\n",
        "            \"state\": state.tolist(),\n",
        "            \"action\": action,\n",
        "            \"next_state\": next_state.tolist(),\n",
        "            \"reward\": reward,\n",
        "            \"threat_detected\": threat_type\n",
        "        })\n",
        "\n",
        "    log_data.append(episode_log)\n",
        "    reward_history.append(total_reward)\n",
        "\n",
        "    # Update Target Network\n",
        "    if episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon = max(MIN_EPSILON, epsilon * EPSILON_DECAY)\n",
        "\n",
        "    # Adjust Learning Rate\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Episode {episode}: Total Reward = {total_reward}, Epsilon = {epsilon:.4f}, LR = {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "    # **Early Stopping Check**: If rewards stabilize over 50 episodes, stop training\n",
        "    if episode > 50 and np.std(reward_history[-50:]) < 1.0:  # Check variance of last 50 episodes\n",
        "        print(f\"Stopping early at Episode {episode} as reward has stabilized.\")\n",
        "        break\n",
        "\n",
        "# Save Logs and Model\n",
        "with open(\"attack_logs.json\", \"w\") as f:\n",
        "    json.dump(log_data, f)\n",
        "\n",
        "torch.save(policy_net.state_dict(), \"dqn_nasim_model.pth\")\n",
        "print(\"Training complete. Model and logs saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "XlTpSJEJUAP3",
        "outputId": "9c94c85b-c708-4542-d76e-4b6a4704ec62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nasim/envs/render.py:17: UserWarning: Unable to import Matplotlib with TkAgg backend due to following exception: \"<class 'ImportError'> Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'headless' is currently running\". NASIM can still run but GUI functionallity may not work as expected.\n",
            "  warnings.warn(\n",
            "<ipython-input-11-50ad7c4a2228>:86: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  states = torch.FloatTensor(states)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Total Reward = 66.0, Epsilon = 0.9970, LR = 0.001000\n",
            "Episode 1: Total Reward = 156.0, Epsilon = 0.9940, LR = 0.001000\n",
            "Episode 2: Total Reward = 10.0, Epsilon = 0.9910, LR = 0.001000\n",
            "Episode 3: Total Reward = 160.0, Epsilon = 0.9881, LR = 0.001000\n",
            "Episode 4: Total Reward = 61.0, Epsilon = 0.9851, LR = 0.001000\n",
            "Episode 5: Total Reward = 119.0, Epsilon = 0.9821, LR = 0.001000\n",
            "Episode 6: Total Reward = 140.0, Epsilon = 0.9792, LR = 0.001000\n",
            "Episode 7: Total Reward = 68.0, Epsilon = 0.9763, LR = 0.001000\n",
            "Episode 8: Total Reward = 35.0, Epsilon = 0.9733, LR = 0.001000\n",
            "Episode 9: Total Reward = 97.0, Epsilon = 0.9704, LR = 0.001000\n",
            "Episode 10: Total Reward = 119.0, Epsilon = 0.9675, LR = 0.001000\n",
            "Episode 11: Total Reward = 82.0, Epsilon = 0.9646, LR = 0.001000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-50ad7c4a2228>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreat_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-50ad7c4a2228>\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Training Loop with Reward Shaping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}